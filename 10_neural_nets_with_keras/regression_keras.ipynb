{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "regression_keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fv3mtVaetfE8"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import matplotlib as mlt\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#build the model \n",
        "#the output layers must be a single neuron for regression, we predict a single value\n",
        "# no activation function\n",
        "# loss function is MSE\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)\n",
        "X_new = X_test[:3]\n",
        "y_pred = model.predict(X_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFpbrVrqu7Fq",
        "outputId": "8e6b94e0-ede4-407a-8e99-25260270fafb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 2s 3ms/step - loss: 1.6419 - val_loss: 0.8560\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.7047 - val_loss: 0.6531\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.6345 - val_loss: 0.6099\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5977 - val_loss: 0.5658\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.5706 - val_loss: 0.5355\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5472 - val_loss: 0.5173\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5288 - val_loss: 0.5081\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5130 - val_loss: 0.4799\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4992 - val_loss: 0.4690\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4875 - val_loss: 0.4656\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4777 - val_loss: 0.4482\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4688 - val_loss: 0.4479\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4615 - val_loss: 0.4296\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4547 - val_loss: 0.4233\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4488 - val_loss: 0.4176\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4435 - val_loss: 0.4123\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4389 - val_loss: 0.4071\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4347 - val_loss: 0.4037\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4306 - val_loss: 0.4000\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4273 - val_loss: 0.3969\n",
            "162/162 [==============================] - 0s 1ms/step - loss: 0.4212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "Ozd_un_avfYu",
        "outputId": "dbba2f24-b6a7-4326-9f36-f93b212203f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#functional API, a complex model called Wide & Deep by Heng-Tze Cheng\n",
        "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
        "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
        "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
        "concat = keras.layers.concatenate([input_, hidden2])\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "model = keras.models.Model(inputs=[input_], outputs=[output])\n",
        "#we pass the precedent model like a function\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "oWGwzJbYvn6G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47986780-0d3b-4e7e-b86d-993454651dbb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 8)]          0           []                               \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 30)           270         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 30)           930         ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 38)           0           ['input_1[0][0]',                \n",
            "                                                                  'dense_7[0][0]']                \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 1)            39          ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,239\n",
            "Trainable params: 1,239\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "zdzY4KnmyfFj",
        "outputId": "29b4fc6f-5079-44ca-f00e-e86a04303ed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "history = model.fit(X_train, y_train, epochs=20,\n",
        "                    validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)\n",
        "y_pred = model.predict(X_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNbzDx8Mywa4",
        "outputId": "164c2d86-b40d-4e9f-f325-964e6bfedb84"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 1.8772 - val_loss: 0.6913\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6501 - val_loss: 0.9454\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.6012 - val_loss: 0.6622\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.5654 - val_loss: 0.5284\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5414 - val_loss: 0.5004\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.5181 - val_loss: 0.5894\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5035 - val_loss: 0.5889\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4904 - val_loss: 0.4690\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4769 - val_loss: 0.5305\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4676 - val_loss: 0.5466\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4601 - val_loss: 0.4996\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4524 - val_loss: 0.7264\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4486 - val_loss: 0.4205\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4415 - val_loss: 0.4467\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4367 - val_loss: 0.4167\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4323 - val_loss: 0.4486\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4286 - val_loss: 0.4021\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4255 - val_loss: 0.3991\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4215 - val_loss: 0.4348\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4192 - val_loss: 0.3965\n",
            "162/162 [==============================] - 0s 2ms/step - loss: 0.4164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#if we want to send different subsets of input features with different paths? lets send 5 features (0 to 4) to wide path and 6 through deep path (2 to 7)\n",
        "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
        "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
        "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
        "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
        "concat = keras.layers.concatenate([input_A, hidden2])\n",
        "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
        "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])\n",
        "\n",
        "keras.utils.plot_model(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "ODuE94Gny84Y",
        "outputId": "e10e97fe-d40d-4c49-c196-6e7503b8a448"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbkAAAHBCAYAAAD0JcWEAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nO3de1xUdf4/8NdhgBkGGBBDQQED1CwvZauGqKWZeStNQaG8pKXrpa3c1NjUzK2sdSlpTa1Vyd+j2mhAWy9Z2WZpVuDapmGokBgaIWKIgHIb4P37o69TE6igzJyZw+v5eMwfnHNmPq8zc2ZezJlzZhQRERAREWlPmpvaCYiIiOyFJUdERJrFkiMiIs1iyRERkWa5/35Ceno6Vq5cqUYWIs3r378/nnjiCbVjELUaDd7J/fjjj9i0aZMaWegq5Ofn8/FyERkZGUhPT1c7BlGr0uCd3EVpaWmOzEFXKTU1FXFxcXy8XMCECRPUjkDU6vAzOSIi0iyWHBERaRZLjoiINIslR0REmsWSIyIizWLJERGRZrHkiIhIs1hyRESkWSw5IiLSLJYcERFpFkuOiIg0iyVHRESaxZIjIiLNYskREZFm2aXkZsyYAV9fXyiKgoMHD9pjiBbxwQcfwM/PD9u3b1c7isNkZGTgxhtvhJubGxRFQfv27fH888+rHcvG5s2bERERAUVRoCgKgoKCMHnyZLVjEZELuuTvyV2LDRs24K677sL9999vj5tvMSKidgSHi4qKwpEjRzBixAjs3LkT2dnZ8Pf3VzuWjZiYGMTExKBz5874+eefUVhYqHYkInJRrXp35ejRo1FaWop7771X7SiorKxEdHS02jFU0ZrXnYjsy24lpyiKvW5ak5KTk1FUVKR2DFW05nUnIvtqkZITESQmJuKGG26AXq+Hn58fFi5c2GC5uro6LF26FGFhYfDy8kKvXr1gNpubNH/VqlUwGAxo164dZs+ejeDgYBgMBkRHR2Pfvn3NzvzFF18gLCwMiqJg9erVAIC1a9fC29sbRqMRW7duxciRI2EymRASEoKUlBTrdZua5bHHHoOnpyeCgoKs0x555BF4e3tDURT8/PPPAIB58+Zh/vz5yM3NhaIo6Ny5c7PX51q5+rrv3bsXN910E/z8/GAwGNCzZ0/s3LkTwC+fEV/8fC8yMhIHDhwAAEyfPh1GoxF+fn7Ytm0bgMtvg3//+99hNBrh6+uLoqIizJ8/Hx07dkR2dvZVZSYiB5DfMZvN0sjky1q8eLEoiiIvv/yylJSUSEVFhaxZs0YAyIEDB6zLLViwQPR6vWzatElKSkpk0aJF4ubmJvv372/S/FmzZom3t7ccPnxYqqqqJCsrS/r27Su+vr5y8uTJZmUWEfnxxx8FgLz66qs26wJAdu3aJaWlpVJUVCSDBg0Sb29vqampsS7X1CyTJk2S9u3b24ybmJgoAOTMmTPWaTExMRIZGdnsdbiax0tEZPjw4QJASkpKrNOcbd0jIyPFz8+vSeuTlpYmy5Ytk7Nnz0pxcbFERUVJ27ZtbcbQ6XTy008/2VzvgQcekG3btln/vtI2ePE+evzxx+XVV1+V8ePHy5EjR5qUMTY2VmJjY5u0LBG1iNRrfidXWVmJpKQk3HXXXXjiiSfg7+8PLy8vBAQE2CxXVVWFtWvXYty4cYiJiYG/vz+WLFkCDw8PbNy48YrzL3J3d8eNN94IvV6Pm266CWvXrkV5ebnNMi0hOjoaJpMJgYGBiI+Px4ULF3Dy5EmbZRyVxdFccd1jY2PxzDPPoE2bNggICMCYMWNQXFyMM2fOAADmzJmDuro6m3xlZWXYv38/Ro0aBeDK2+hv/e1vf8Of/vQnbN68Gd26dXPcihJRs1xzyR07dgwVFRUYOnToZZfLzs5GRUUFevToYZ3m5eWFoKAgHD169IrzL6VPnz4wGo2XXeZaeXp6AgAsFstll3NEFkdz1XX38PAA8MvuRwC488470bVrV7zxxhvWo2rfffddxMfHQ6fTAbjyNkpErueaSy4/Px8AEBgYeNnlLly4AABYsmSJ9fMRRVFw4sQJVFRUXHH+5ej1eut/7GpzpiyOpua679ixA4MHD0ZgYCD0ej2efPJJm/mKomD27Nk4fvw4du3aBQB488038fDDD1uXuZZtkIic0zWXnMFgAABUV1dfdrmLJZiUlAQRsbmkp6dfcf6lWCwWnDt3DiEhIde6KtfMmbI4mqPX/fPPP0dSUhIA4OTJkxg3bhyCgoKwb98+lJaWYsWKFQ2uM23aNBgMBmzYsAHZ2dkwmUzo1KmTdf7VboNE5LyuueR69OgBNzc37Nmz57LLhYaGwmAwXPIbUK40/1J2794NEUFUVFSzrmcPjWVxd3e/4q4+LXD0uv/vf/+Dt7c3AODQoUOwWCyYO3cuIiIiYDAYGj2FpU2bNoiLi8OWLVvw0ksvYebMmTbzr3YbJCLndc0lFxgYiJiYGGzatAnJyckoKytDZmYm1q1bZ7OcwWDA9OnTkZKSgrVr16KsrAx1dXXIz8/HqVOnrjj/ovr6epSUlKC2thaZmZmYN28ewsLCMG3atGtdlWZrSpbOnTvj7Nmz2LJlCywWC86cOYMTJ040uK2AgAAUFBQgLy8P5eXlTl+Maq27xWLB6dOnsXv3bmvJhYWFAQA++eQTVFVV4fvvv7/kaSVz5sxBdXU13n///QZfAtDUbZCIXMjvj7e8mkPSy8vLZcaMGdK2bVvx8fGRgQMHytKlSwWAhISEyLfffisiItXV1ZKQkCBhYWHi7u4ugYGBEhMTI1lZWU2aP2vWLPHw8JCOHTuKu7u7mEwmue+++yQ3N7e5h5XKq6++KkFBQQJAjEajjBkzRtasWSNGo1EASJcuXSQ3N1fWrVsnJpNJAEinTp0kJyenWVmKi4tlyJAhYjAYJDw8XB599FFZuHChAJDOnTtbD7n/5ptvpFOnTuLl5SUDBw6UwsLCJq1Hcx+vjIwM6d69u7i5uQkACQoKkuXLlzvVur/22msSGRkpAC57ee+996xjJSQkSEBAgPj7+8uECRNk9erVAkAiIyMbnF7Su3dveeqppxq9fy63Da5YsUK8vLwEgISGhspbb73V5PtdhKcQEKkgVRGx/QLH1NRUxMXFOeX3Os6ePRtpaWkoLi5WO4rTZFHj8XKWdb9ao0ePxurVqxEeHu7QcSdMmAAASEtLc+i4RK1Ymst9d+XFQ8KdgTNlcTRXWvff7v7MzMyEwWBweMERkTpcruQu5+jRozaHfl/qEh8fr3ZUcqCEhAR8//33yMnJwfTp0/Hcc8+pHYmIHMRlSm7RokXYuHEjSktLER4ejk2bNjVYplu3bg0O/W7s8u6779o9i1a54robjUZ069YNd911F5YtW4abbrpJ7UhE5CAu9ZkcNcTHy3XwMzkih3O9z+SIiIiaiiVHRESaxZIjIiLNYskREZFmseSIiEizWHJERKRZLDkiItIslhwREWkWS46IiDSLJUdERJrFkiMiIs1iyRERkWax5IiISLPcLzXj4jemk3PLz88HwMfLFWRkZCAqKkrtGEStSoN3cqGhoYiNjVUjC12Fb775BtHR0WrHoCaIiopC//791Y5B1Ko0+D05ci2KosBsNmPixIlqRyEicjb8PTkiItIulhwREWkWS46IiDSLJUdERJrFkiMiIs1iyRERkWax5IiISLNYckREpFksOSIi0iyWHBERaRZLjoiINIslR0REmsWSIyIizWLJERGRZrHkiIhIs1hyRESkWSw5IiLSLJYcERFpFkuOiIg0iyVHRESaxZIjIiLNYskREZFmseSIiEizWHJERKRZLDkiItIslhwREWkWS46IiDSLJUdERJrFkiMiIs1iyRERkWax5IiISLNYckREpFksOSIi0ixFRETtENQ0U6ZMwcGDB22m5eXlITAwEN7e3tZpHh4e2L59Ozp27OjoiEREziTNXe0E1HQ33HAD3n777QbTz58/b/N3t27dWHBERODuSpdy//33Q1GUyy7j4eGBadOmOSYQEZGTY8m5kMjISPTu3Rtubpd+2GpraxEXF+fAVEREzosl52KmTp16yZJTFAX9+vXD9ddf79hQREROiiXnYuLi4lBfX9/oPDc3N0ydOtXBiYiInBdLzsUEBQVh0KBB0Ol0jc6PiYlxcCIiIufFknNBU6ZMaTDNzc0NQ4YMQfv27VVIRETknFhyLmjChAmNfi7XWPkREbVmLDkXZDKZMGLECLi7/3qao06nw9ixY1VMRUTkfFhyLmry5Mmoq6sDALi7u2PMmDHw8/NTORURkXNhybmoMWPGwMvLCwBQV1eHSZMmqZyIiMj5sORclMFgwPjx4wEARqMRI0eOVDkREZHzcZrvrszPz8dXX32ldgyXEhoaCgDo27cvtm3bpnIa1xIaGor+/furHYOI7MxpfoUgNTWVX0dFDhMbG4u0tDS1YxCRfaU53e5KEeGlGZdnnnkGFovlkvMBwGw2q57TmS6xsbEqb+VE5ChOV3LUPEuWLLE5lYCIiH7FknNxLDgioktjyRERkWax5IiISLNYckREpFksOSIi0iyWHBERaRZLjoiINIslR0REmsWSIyIizWLJERGRZrHkiIhIs1hyRESkWSw5IiLSLE2V3IwZM+Dr6wtFUXDw4EG141wVi8WCpUuXIiIiAp6enujYsSMWLFiAyspKu4+9efNmREREQFEUm4unpyfatWuHwYMHIzExESUlJXbPQkTUEjRVchs2bMD69evVjnFN5s2bh8TERLzwwgsoLi7Gv/71L6xfvx4zZsyw+9gxMTE4fvw4IiMj4efnBxFBfX09ioqKkJqaivDwcCQkJKB79+74+uuv7Z6HiOhaaarkXN3x48fx+uuvY+rUqYiPj4evry8GDx6Mxx57DO+88w6OHDni8EyKosDf3x+DBw/Gxo0bkZqaitOnT2P06NEoLS11eB4ioubQXMkpiqJ2hKu2f/9+1NfX47bbbrOZPmLECADAzp071YhlIzY2FtOmTUNRURFef/11teMQEV2WS5eciCAxMRE33HAD9Ho9/Pz8sHDhwgbL1dXVYenSpQgLC4OXlxd69eoFs9kMAFi7di28vb1hNBqxdetWjBw5EiaTCSEhIUhJSbG5nT179qBfv34wGo0wmUzo2bMnysrKrjhGU7m5/fJweHl52Uzv0qULAKjyTq4x06ZNAwB8+OGH1mmuch8TUSsjTsJsNktz4yxevFgURZGXX35ZSkpKpKKiQtasWSMA5MCBA9blFixYIHq9XjZt2iQlJSWyaNEicXNzk/3791tvB4Ds2rVLSktLpaioSAYNGiTe3t5SU1MjIiLnz58Xk8kkK1askMrKSiksLJTx48fLmTNnmjRGU2RmZgoAefrpp22m19bWCgAZN25cs+4fEREAYjabm3WdyMhI8fPzu+T8srIyASChoaHWaa5yH4uIxMbGSmxsbLOuQ0QuKdVlS66iokKMRqMMGzbMZnpKSopNyVVWVorRaJT4+Hib6+r1epk7d66I/PoCXFlZaV3mYlkeO3ZMRES+++47ASDvv/9+gyxNGaOpRowYIQEBAbJr1y6prKyUU6dOSWpqqiiKIvfcc0+zbkvEPiUnIqIoivj7+4uI693HLDmiViPVZXdXHjt2DBUVFRg6dOhll8vOzkZFRQV69Ohhnebl5YWgoCAcPXr0ktfz9PQE8Msh/QAQERGBdu3aYfLkyVi2bBny8vKueYzGvPvuu5gwYQKmTp2KgIAADBgwAP/+978hImjbtm2zbsteLly4ABGByWQC4Hr3MRG1Hi5bcvn5+QCAwMDAyy534cIFAMCSJUtszv06ceIEKioqmjyel5cXPv30UwwcOBDLly9HREQE4uPjUVlZ2WJjAICfnx9ef/115Ofno6KiArm5uXj55ZcBAB06dGjWbdlLTk4OAKBbt24AXO8+JqLWw2VLzmAwAACqq6svu9zFEkxKSoKI2FzS09ObNWb37t2xfft2FBQUICEhAWazGS+99FKLjtGY/fv3AwCGDBlyzbfVEj766CMAwMiRIwFo4z4mIm1y2ZLr0aMH3NzcsGfPnssuFxoaCoPBcM3fgFJQUIDDhw8D+OVF/cUXX8Stt96Kw4cPt9gYl7J+/XqEh4fjjjvusMvtN0dhYSGSkpIQEhKChx56CIA27mMi0iaXLbnAwEDExMRg06ZNSE5ORllZGTIzM7Fu3Tqb5QwGA6ZPn46UlBSsXbsWZWVlqKurQ35+Pk6dOtXk8QoKCjB79mwcPXoUNTU1OHDgAE6cOIGoqKgWGwMA+vXrhxMnTqC2thZ5eXlYsGABPvnkEyQnJ1s/w3IEEcH58+dRX18PEcGZM2dgNpsxYMAA6HQ6bNmyxfqZnKvdx0TUijj2QJdLu5pTCMrLy2XGjBnStm1b8fHxkYEDB8rSpUsFgISEhMi3334rIiLV1dWSkJAgYWFh4u7uLoGBgRITEyNZWVmyZs0aMRqNAkC6dOkiubm5sm7dOjGZTAJAOnXqJDk5OZKXlyfR0dHSpk0b0el00qFDB1m8eLHU1tZecYzmGDZsmPj7+4u7u7u0adNGRo8e3exD5H8LzTi6ctu2bdKrVy8xGo3i6ekpbm5uAsB6JGW/fv3k2WefleLi4gbXdaX7mEdXErUaqYqIiHoV+6vU1FTExcXBSeJohqIoMJvNmDhxotpRnMaECRMAAGlpaSonISI7S3PZ3ZVERERXwpKzs6NHjzb46ZrGLvHx8WpHJSLSHHe1A2hdt27duAuWiEglfCdHRESaxZIjIiLNYskREZFmseSIiEizWHJERKRZLDkiItIslhwREWkWS46IiDSLJUdERJrFkiMiIs1iyRERkWax5IiISLNYckREpFksOSIi0iyn+6md1NRUtSNoTnp6utoRnEp+fj5CQkLUjkFEDqCIk/zYWWpqKuLi4tSOQa1EbGws0tLS1I5BRPaV5jQlR1dHURSYzWZMnDhR7ShERM4mjZ/JERGRZrHkiIhIs1hyRESkWSw5IiLSLJYcERFpFkuOiIg0iyVHRESaxZIjIiLNYskREZFmseSIiEizWHJERKRZLDkiItIslhwREWkWS46IiDSLJUdERJrFkiMiIs1iyRERkWax5IiISLNYckREpFksOSIi0iyWHBERaRZLjoiINIslR0REmsWSIyIizWLJERGRZrHkiIhIs1hyRESkWSw5IiLSLJYcERFpFkuOiIg0iyVHRESaxZIjIiLNYskREZFmuasdgJpu3bp1KCkpaTB969at+OGHH2ymTZs2De3bt3dUNCIip6SIiKgdgppm1qxZWLduHfR6vXWaiEBRFOvftbW18PPzQ2FhITw8PNSISUTkLNK4u9KF3H///QCA6upq66Wmpsbmbzc3N9x///0sOCIi8DM5l3L77bejXbt2l13GYrFYy5CIqLVjybkQNzc3TJ48GZ6enpdcJjg4GNHR0Q5MRUTkvFhyLub+++9HTU1No/M8PDwwdepUm8/oiIhaM5aci+nTpw/Cw8MbncddlUREtlhyLmjq1KmNHlgSERGBm2++WYVERETOiSXngiZPngyLxWIzzcPDA9OnT1cpERGRc2LJuaDOnTujZ8+eNp+9WSwWxMXFqZiKiMj5sORc1NSpU6HT6QAAiqKgd+/e6NKli8qpiIicC0vORT3wwAOoq6sDAOh0Ojz44IMqJyIicj4sORfVoUMHREdHQ1EU1NfXY8KECWpHIiJyOiw5FzZlyhSICG6//XZ06NBB7ThERE5HtS9o5gnL5GzMZjMmTpxol9tOTU3lgUFEdtZInaWp+lM78+bNQ//+/dWM4PJefvllzJo1Cz4+Pk1aPj09Ha+88grMZrOdk7kWRxUQ73fXEhcXx9cpF3Dxda0xqpZc//797fafc2sRHR2NkJCQZl3nlVde4f3+O44qOd7vriUuLo6vUy7iUiXHz+RcXHMLjoioNWHJERGRZrHkiIhIs1hyRESkWSw5IiLSLJYcERFpFkuOiIg0iyVHRESaxZIjIiLNYskREZFmseSIiEizWHJERKRZLDkiItIslhwREWmWy5bcjBkz4OvrC0VRcPDgQbXjXJP6+nokJSUhOjr6kst88cUXGDBgAIxGI4KDg5GQkIDq6mq7Z9u8eTMiIiKgKIrNxdPTE+3atcPgwYORmJiIkpISu2ehpvnggw/g5+eH7du3X3IZez9/mpJBazIyMnDjjTfCzc0NiqKgffv2eP7559WOZeP3z+egoCBMnjxZ7Vh25bIlt2HDBqxfv17tGNfs+++/x+23344nnngCFRUVjS6TlZWFu+++G0OHDsWZM2fw3nvv4Y033sCcOXPsni8mJgbHjx9HZGQk/Pz8ICKor69HUVERUlNTER4ejoSEBHTv3h1ff/213fPQlTXy68gN2Pv505QMWhMVFYUjR47g7rvvBgBkZ2djyZIlKqey9fvnc2FhId5++221Y9mVy5acFnz77bf4y1/+gjlz5uCWW2655HLPPfccgoKC8Ne//hXe3t7o378/EhIS8P/+3//D0aNHHZj4F4qiwN/fH4MHD8bGjRuRmpqK06dPY/To0SgtLXV4HrJ18XG49957W3WGiyorKy+7l0TLWvO6X+TSJacoitoRrsnNN9+MzZs3Y9KkSdDr9Y0uU1tbix07duCOO+6wWd+RI0dCRLB161ZHxb2k2NhYTJs2DUVFRXj99dfVjkNN5OrPn6ZKTk5GUVGR2jFU0ZrX/SKXKTkRQWJiIm644Qbo9Xr4+flh4cKFDZarq6vD0qVLERYWBi8vL/Tq1QtmsxkAsHbtWnh7e8NoNGLr1q0YOXIkTCYTQkJCkJKSYnM7e/bsQb9+/WA0GmEymdCzZ0+UlZVdcYyWdvz4cZw/fx5hYWE20yMjIwEAmZmZdhm3uaZNmwYA+PDDD63TtPZYOFKfPn2sn5v06tULP/74Y6PLLVu2DAEBATAYDHj++efxxRdfICwsDIqiYPXq1dblWuL501SNZWjq471q1SoYDAa0a9cOs2fPRnBwMAwGA6Kjo7Fv3z7rco899hg8PT0RFBRknfbII4/A29sbiqLg559/BgDMmzcP8+fPR25uLhRFQefOnZu1Li3B1dd97969uOmmm+Dn5weDwYCePXti586dAH75bPfidhoZGYkDBw4AAKZPnw6j0Qg/Pz9s27YNwOW3rb///e8wGo3w9fVFUVER5s+fj44dOyI7O/uqMtsQlQAQs9nc5OUXL14siqLIyy+/LCUlJVJRUSFr1qwRAHLgwAHrcgsWLBC9Xi+bNm2SkpISWbRokbi5ucn+/futtwNAdu3aJaWlpVJUVCSDBg0Sb29vqampERGR8+fPi8lkkhUrVkhlZaUUFhbK+PHj5cyZM00a42rcdtttcvPNNzeYvmfPHgEgiYmJDeZ5eXnJ0KFDmzWO2WyWq3nYIyMjxc/P75Lzy8rKBICEhoZap7nSY9Hc7bG5ruZ+HzBggISGhkp9fb112vbt26Vr1642y61atUqWL19u/fvHH38UAPLqq69ap7XU86epLpXhSo+3iMisWbPE29tbDh8+LFVVVZKVlSV9+/YVX19fOXnypHW5SZMmSfv27W3GTUxMFADW7UNEJCYmRiIjI5uV/6Kr2S6GDx8uAKSkpMQ6zdnW/UrP599KS0uTZcuWydmzZ6W4uFiioqKkbdu2NmPodDr56aefbK73wAMPyLZt26x/N/X14PHHH5dXX31Vxo8fL0eOHGlSxss8v1JdouQqKirEaDTKsGHDbKanpKTYPEkrKyvFaDRKfHy8zXX1er3MnTtXRH69IysrK63LXHyyHzt2TEREvvvuOwEg77//foMsTRnjalyq5D7++GMBICtXrmwwz2QySXR0dLPGsVfJiYgoiiL+/v4i4nqPhTOW3Pr16wWAfPrpp9ZpsbGxAkC++uor67QBAwbIiRMnrH//vmBa8vnTVJcrucs93iK/vND/flvbv3+/AJC//vWv1mmuWHLOsu7NKbnfe+GFFwSAFBUViYjIJ598IgDk+eefty5TWloqXbp0kdraWhG5+teDprpcybnE7spjx46hoqICQ4cOvexy2dnZqKioQI8ePazTvLy8EBQUdNkDNDw9PQEAFosFABAREYF27dph8uTJWLZsGfLy8q55jKtlMBgA/PLZ3O/V1NTAy8urxce8GhcuXICIwGQyAdDmY+FocXFxMBqNePPNNwEAJSUlyM3NhV6vt07Ly8uDp6dng93Zv2Xv58+1+P3jfSl9+vSB0WjUxON6kauuu4eHB4Bfdj8CwJ133omuXbvijTfesB5V++677yI+Ph46nQ6Aus9Vlyi5/Px8AEBgYOBll7tw4QIAYMmSJTbndJ04ceKSh+c3xsvLC59++ikGDhyI5cuXIyIiAvHx8aisrGyxMZrq4n73i59BXVRRUYGqqioEBwe3+JhXIycnBwDQrVs3ANp8LBzN19cX48ePx+bNm1FRUYGUlBQ8/PDDuPfee2E2m1FdXY2UlJQrnufk6OePvej1epw5c0btGKpQc9137NiBwYMHIzAwEHq9Hk8++aTNfEVRMHv2bBw/fhy7du0CALz55pt4+OGHrcuouW25RMldfDdzpZOfLz6Jk5KSICI2l/T09GaN2b17d2zfvh0FBQVISEiA2WzGSy+91KJjNEV4eDh8fX1x4sQJm+nHjh0DAPTq1avFx7waH330EYBfjvoEtPlYqGH69OkoLy/Hv//9b6SkpCA+Ph7Tp09HSUkJ3n//fWzZsgWxsbGXvQ01nj8tzWKx4Ny5cwgJCVE1hxocve6ff/45kpKSAAAnT57EuHHjEBQUhH379qG0tBQrVqxocJ1p06bBYDBgw4YNyM7OhslkQqdOnazz1dy2XKLkevToATc3N+zZs+eyy4WGhsJgMFzzNzgUFBTg8OHDAH55cF588UXceuutOHz4cIuN0VTu7u4YNWoUPv/8c9TX11unf/jhh1AUBWPGjHFIjsspLCxEUlISQkJC8NBDDwHQ5mOhhiFDhqBTp054/vnn0a5dO7Rt2xbDhw9HcHAwnnnmGYSHh1t3EV+Ko58/9rB7926ICKKioqzT3N3dr7irTwscve7/+9//4O3tDQA4dBMDD2oAACAASURBVOgQLBYL5s6di4iICBgMhkZPPWnTpg3i4uKwZcsWvPTSS5g5c6bNfDW3LZcoucDAQMTExGDTpk1ITk5GWVkZMjMzsW7dOpvlDAYDpk+fjpSUFKxduxZlZWWoq6tDfn4+Tp061eTxCgoKMHv2bBw9ehQ1NTU4cOAATpw4gaioqBYbozmefvppnD59Gs888wwuXLiA9PR0JCYmYtq0abjhhhvsMmZjRATnz59HfX09RARnzpyB2WzGgAEDoNPpsGXLFusLrlYfC0dTFAUPPvggjh49igcffBAAoNPpMGXKFGRlZWHKlClXvA1HP39aQn19PUpKSlBbW4vMzEzMmzcPYWFh1lNVAKBz5844e/YstmzZAovFgjNnzjTY4wEAAQEBKCgoQF5eHsrLy52+GNVad4vFgtOnT2P37t3Wkrv4We8nn3yCqqoqfP/99zanM/zWnDlzUF1djffff7/BlwCoum01+zCWFoJmHrVUXl4uM2bMkLZt24qPj48MHDhQli5dKgAkJCREvv32WxERqa6uloSEBAkLCxN3d3cJDAyUmJgYycrKkjVr1ojRaBQA0qVLF8nNzZV169aJyWQSANKpUyfJycmRvLw8iY6OljZt2ohOp5MOHTrI4sWLrUcKXW6M5khPT5cBAwZIcHCwABAAEhQUJNHR0bJnzx6bZffs2SP9+vUTvV4vwcHBsnDhQqmqqmrWeCLNP8pv27Zt0qtXLzEajeLp6Slubm4CwHokZb9+/eTZZ5+V4uLiBtd1pceiudtjc13tUa0iIsePH5d27drZHGp+5MgRadeunVgsFptlX331VQkKChIAYjQaZcyYMSLSMs+fpmosQ1Mfb5FfjjD08PCQjh07iru7u5hMJrnvvvskNzfXZpzi4mIZMmSIGAwGCQ8Pl0cffVQWLlwoAKRz587WQ+6/+eYb6dSpk3h5ecnAgQOlsLCwyevSnO0iIyNDunfvbn2OBAUFyfLly51q3V977TWJjIy0vt5c6vLee+9Zx0pISJCAgADx9/eXCRMmyOrVqwWAREZG2pzWICLSu3dveeqppxq9fy63ba1YsUK8vLyspyG99dZbTX6MRDRwCgG1nGt5sdUyZy651mbWrFkSEBCgdgwRcfzrlDOt+9UYNWqUHD9+3OHjuvwpBETUulw8PL01cqV1/+3uz8zMTBgMBoSHh6uYqCGWXAs6evRog5+kaewSHx+vdlSiZuG2TY1JSEjA999/j5ycHEyfPh3PPfec2pEacFc7gJZ069atVf7ECGmfo7btRYsWYePGjaipqUF4eDgSExOveIqEVrjiuhuNRnTr1g0dO3bEmjVrcNNNN6kdqQG+kyMip/HCCy+guroaIoIffvjB6V/kW5Irrvvzzz+Puro6nDx50il+VqkxLDkiItIslhwREWkWS46IiDSLJUdERJrFkiMiIs1iyRERkWax5IiISLNYckREpFksOSIi0iyWHBERaRZLjoiINIslR0REmsWSIyIizVL1p3bi4uIQFxenZoRWS1EUtSO0SrzfXQ9fp1ybaiVnNpvVGpquwqlTp/DMM8/guuuuw1NPPQVfX1+1I7W46Ohou942t/mrd+jQIbz88su44YYb8Je//IX/LFCTKcJf+aQm+uGHH3D33XdDRLBz505ERkaqHYlagc2bN2Py5MmIiYnBG2+8AU9PT7UjketI42dy1GTh4eHYu3cvfH19MWjQIHz77bdqRyKNW7VqFSZOnIg//vGPePPNN1lw1GwsOWqWoKAgfPbZZ+jSpQuGDBmCL774Qu1IpEEigmXLlmHevHl4+umn8Y9//ANubny5oubjVkPN5u/vj48//hhDhw7F8OHDsWPHDrUjkYbU1tZi5syZWL58OTZs2IBly5apHYlcGEuOroper8e7776LSZMmYezYsUhOTlY7EmnAhQsXMHbsWLz77rvYtm0bHnroIbUjkYtT9RQCcm06nQ7//Oc/0aFDB8ycORPFxcV48skn1Y5FLurs2bO49957kZ2djf/85z/o37+/2pFIA1hydE0URcGyZcvQtm1bzJs3Dz/99BOSkpL4+Qk1S15eHkaMGIGamhp89dVX6Nq1q9qRSCNYctQiHn30UQQEBGD69OkoKSlBcnIyPDw81I5FLuC7777DiBEjEBAQgF27dqFjx45qRyIN4b/b1GImTZqEDz/8EFu2bMH48eNRUVGhdiRycp999hkGDhyIrl274osvvmDBUYtjyVGLGjp0KHbt2oWMjAzceeedKC4uVjsSOal///vfGDVqFIYOHYoPPvgAJpNJ7UikQSw5anF9+/bF559/joKCAtx+++3Iz89XOxI5mdWrVyM2NhYzZ85EWloaDAaD2pFIo1hyZBc33ngjMjIyoNPpMHDgQGRnZ6sdiZzAxZO8H3vsMTz99NNYtWoVD1Iiu+LWRXbToUMH7NmzBx07dkR0dDQyMjLUjkQqqqurw6xZs7B8+XKsW7eOJ3mTQ7DkyK7atGmDjz/+GLfddhvuuusu7Ny5U+1IpIKKigqMHTsW77zzDrZu3YoZM2aoHYlaCZYc2Z23tze2bduGiRMnYsyYMfzJmVbm7NmzuPvuu5Geno6PP/4Yo0aNUjsStSI8T44cwt3dHcnJyWjbti3uv/9+FBQU4M9//rPascjOTpw4gREjRqCqqgpfffUVbrjhBrUjUSvDkiOHURQFiYmJuO666zB//nycPn0af/vb39SORXaSlZWFESNGwN/fH3v37kVISIjakagVYsmRwyUkJCAoKAgzZsxAWVkZVq9ezSPsNGbPnj0YO3YsevfujS1btsDPz0/tSNRKseRIFQ8++CDatGmD+Ph4nDp1CikpKTxXSiO2bNmCBx54ACNGjMA777zDx5VUxX+fSTVjxozBhx9+iM8++wyjRo1CWVmZ2pHoGq1ZswYxMTF46KGHsGnTJhYcqY4lR6q644478MUXXyAnJwd33nknioqK1I5EV2nFihV49NFH8fTTT3MXNDkNRURE7RBEP/zwA4YPH466ujrs3LkTnTt3VjsSNVFdXR3mzp2L5ORkvPbaa5g5c6bakYguSuO/WuQUwsPDsXfvXvj5+WHQoEE4ePCg2pGoCaqrqxEXF4e3334bW7duZcGR02HJkdNo3749Pv/8c/Ts2RNDhgzB3r171Y5El1FSUoK77roLn332GT7++GOMHj1a7UhEDbDkyKn4+Phg+/btGDZsGIYNG4bNmzerHYkaUVBQgDvuuAM//vgjvvzySwwYMEDtSESNYsmR09Hr9UhJScG0adMQFxeH9evXqx2JfiMrKwtRUVGor6/HF198gW7duqkdieiSeJ4cOSWdTofXX38d4eHhmDVrFn766Sd+a70TyMjIwD333IMePXpgy5Yt8Pf3VzsS0WWx5MipJSQkwMfHB4899hhKSkqQlJTEQ9NVsnXrVtx///0YPnw43nnnHXh5eakdieiKWHLk9B555BEEBwfjgQcewNmzZ/HGG2/Aw8ND7VitysaNG/HHP/4RU6dOxT//+U+4u/Olg1wD/yUmlzB+/Hh88MEH2Lp1K0aNGoXz58+rHanVWLFiBR566CHMnz8fycnJLDhyKTwZnFzK119/jVGjRiE8PBw7duzAddddp3Ykzaqrq8Of/vQnrF+/HmvWrMGsWbPUjkTUXGksOXI5R48exfDhw+Hj44OPPvoIoaGhakfSnOrqakyePBnbt2/H22+/jdjYWLUjEV0NfuMJuZ5u3bohIyMD7u7uGDRoELKzs9WOpCklJSUYNmwYdu3ahU8++YQFRy6NJUcuKTg4GLt370ZISAiio6ORnp6udiRNKCgowJAhQ5Cbm4vdu3dj4MCBakciuiYsOXJZbdq0wccff4yoqCgMGzYMH330UaPLlZeXY/v27Q5O55z27NmDc+fONTrvyJEj6N+/PywWCzIyMtCrVy8HpyNqeSw5cmlGoxFbt25FXFwcxo4di3fffddmfk1NDcaOHYsHH3wQpaWlKqV0DjU1NXjwwQcxevRoVFVV2czbt28fbr/9dnTo0AF79uzh55ykGSw5cnnu7u7YsGEDHn/8cTzwwANYuXIlAKC+vh6TJ0/G3r17UV5ejr///e8qJ1XXa6+9hvz8fPz3v/9FfHw86urqAADbt2/HnXfeiejoaHz66ac8YpU0hUdXkqb84x//wJ///Gc8+eSTqKysxOrVq1FfXw8A8PT0RG5uLkJCQlRO6XilpaW4/vrrrbsqdTodpk+fjgEDBmDmzJmYMmUK1q1bx3PgSGt4CgFpzxtvvIGFCxeipKQEv928PTw8MG3aNKxbt07FdOp46qmn8NJLL6G2ttY6zc3NDUFBQZg5cya/F5S0iqcQkPZYLBacPXsWv///zWKxIDk5GUeOHFEpmTp++uknJCUl2RQc8Mvu3IKCAu6eJE1jyZGmbN26FXPnzr3kfJ1Oh0WLFjkwkfoWLVpk3WXbmMcffxzvvfeeAxMROQ53V5JmfPbZZxg+fDhqa2sbvIv7LUVR8NVXXyEqKsqB6dSRmZmJW2655Yr3h4eHBz799FP++ClpDXdXkjZUVlbi8ccfh8ViueJP8eh0OixYsMBBydS1YMGCJh1MUlNTgylTpvCLr0lzWHKkCV5eXjh48CD+85//YNiwYVAUBZ6eno0uW1tbiy+//BI7duxwcErH+uyzz/Cf//wHFoul0fkX75+IiAi88soryMzMhI+PjyMjEtkdd1eSJuXk5GD16tVYv349amtrGxx0odPp0KVLF3z33XfQ6XQqpbSf+vp69O7dG1lZWdbz4S5yd3dHfX09hg8fjieeeAJDhw6FoigqJSWyK+6uJG3q2rUrVq1ahdOnT2PNmjWIiIgAAOuuu7q6OuTk5ODtt99WM6bd/Otf/8KhQ4esBefm5gZFUdC2bVvMnz8feXl5+OCDD3DXXXex4EjT+E6OWoX6+nrs2LEDSUlJ2L17Nzw8PFBTU4Pg4GAcP34cBoNB7YgtpqqqCpGRkSgoKICHhwcsFguio6Px+OOPY9y4cfxVdWpNeDK42iZMmKB2hFanvLwcx44dQ15eHurq6tCrVy907dpV7VgtJicnB5mZmdDpdOjUqRMiIyPh5+endqxWpX///njiiSfUjkFAGr/DR2WbNm1CVFRUq/yqKbX4+vqid+/e6NGjB/Ly8vDjjz8iPDxc1Xc4+fn5yMjIuObfbqupqUF+fj5uueUWdOrUie/aVJCRkaF2BPoNlpwT+POf/4yJEyeqHaPVqq+vR2VlJby9vVXLkJqairi4OKSlpV3T7Vy4cAFGo5Gfs6mIe2ecC0uOWj03NzdVC64laWU9iFoKj64kIiLNYskREZFmseSIiEizWHJERKRZLDkiItIslhwREWkWS46IiDSLJUdERJrFkiMiIs1iyRERkWax5IiISLNYckREpFksOSIi0iyWHNE1qK+vR1JSEqKjo1XLkJ2djUcffRTdu3eHr68v3N3d4efnh65du2L06NFIT09XLRuR2lhyRFfp+++/x+23344nnngCFRUVqmRITk5Gz549kZmZiZUrV+LHH3/EhQsXcODAATz33HM4d+4cDh06pEo2ImfAkiO7qqysVO1djj3H/vbbb/GXv/wFc+bMwS233GKXMa4kIyMDs2bNwqBBg7Br1y4MHz4c/v7+0Ov1iIiIQFxcHJYuXYqamhpV8jWFVrcPch780VSyq+TkZBQVFWlu7JtvvhmbN28GALz66quoqqqyyziX8/zzz6Ourg4vvvgi3N0bfyoPHz4cw4cPd3CyptPq9kHOg+/kXNBbb72FPn36wGAwwNvbG9dffz2ee+45AICIYOXKlbjxxhuh1+vRpk0b3HfffTh69Kj1+mvXroW3tzeMRiO2bt2KkSNHwmQyISQkBCkpKc0ab+/evbjpppvg5+cHg8GAnj17YufOnQCAefPmYf78+cjNzYWiKOjcuTMAoK6uDkuXLkVYWBi8vLzQq1cvmM3mZmdr6bFdSU1NDXbt2oW2bduiX79+Tb4et4/WsX3QbwipCoCYzeYmL5+UlCQA5MUXX5Ti4mI5e/as/POf/5RJkyaJiMjSpUvF09NT3nrrLTl37pxkZmbKrbfeKtddd50UFhZab2fx4sUCQHbt2iWlpaVSVFQkgwYNEm9vb6mpqWnyeGlpabJs2TI5e/asFBcXS1RUlLRt29Z6/ZiYGImMjLRZhwULFoher5dNmzZJSUmJLFq0SNzc3GT//v3NymaPsa/GbbfdJjfffPNVX19ExGw2S3Oejjk5OQJAoqKimjUOtw/7bx+xsbESGxvb5OXJrlJZciprTsnV1NSIv7+/DBkyxGZ6bW2tvPLKK1JRUSE+Pj4SHx9vM/+///2vAJBnn33WOu3iC0VlZaV12po1awSAHDt2rEnjNeaFF14QAFJUVCQiDV9IKisrxWg02mSsqKgQvV4vc+fObXI2e419NdQoua+//loAyF133dXk63D7cMz2wZJzKqncXelCMjMzce7cuQafseh0Ojz++OPIysrC+fPn0adPH5v5ffv2haenJ/bt23fZ2/f09AQAWCyWJo3XGA8PDwC/7PZpTHZ2NioqKtCjRw/rNC8vLwQFBdnsMrtSNkeO7Yx8fHwAoFlHdXL7aD3bB/2KJedCysrKAAD+/v6Nzj937hyAX18Af8vf3x/l5eUtOh4A7NixA4MHD0ZgYCD0ej2efPLJy97mhQsXAABLliyBoijWy4kTJ5p9GL6aY6vt+uuvh8FgQE5OTpOvw+2j9Wwf9CuWnAvp0KEDAODnn39udP7FF5vGXqzOnTuHkJCQFh3v5MmTGDduHIKCgrBv3z6UlpZixYoVl73NwMBAAEBSUhJExObSnJOW1RzbGej1egwfPhw///wzvvzyy0sud/bsWcyYMQMAt4/WtH3Qr1hyLuT6669HQEAAPv7440bn9+jRAz4+Pvj6669tpu/btw81NTX4wx/+0KLjHTp0CBaLBXPnzkVERAQMBgMURbnsbYaGhsJgMODgwYPNyuJMYzuLZcuWQa/X44knnkBlZWWjy3z33XfW0wu4fbSu7YN+wZJzIXq9HosWLcLnn3+Oxx57DD/99BPq6+tRXl6Ow4cPw2AwYP78+Xjvvffw9ttvo6ysDIcOHcKcOXMQHByMWbNmteh4YWFhAIBPPvkEVVVV+P777xt8rhMQEICCggLk5eWhvLwcOp0O06dPR0pKCtauXYuysjLU1dUhPz8fp06danI2Ncd2Frfccgv+9a9/4bvvvsOgQYPwwQcfoLS0FBaLBT/88APWr1+Phx9+2PpZFLeP1rV90P9x/MEu9Fto5ikEIiKrV6+Wnj17isFgEIPBIL1795Y1a9aIiEh9fb0kJiZKly5dxMPDQ9q0aSPjxo2T7Oxs6/XXrFkjRqNRAEiXLl0kNzdX1q1bJyaTSQBIp06dJCcnp0njJSQkSEBAgPj7+8uECRNk9erVAkAiIyPl5MmT8s0330inTp3Ey8tLBg4cKIWFhVJdXS0JCQkSFhYm7u7uEhgYKDExMZKVldWsbC09dnOkp6fLgAEDJDg4WAAIAAkKCpLo6GjZs2dPs25LpPlHV/7WyZMnZcGCBdKzZ0/x8fERnU4n/v7+0rt3b3n44Yflyy+/tC7L7cP+2wePrnQqqYqIiOOrlS5SFAVmsxkTJ05UOwqpKDU1FXFxceDT0fVNmDABAJCWlqZyEgKQxt2VRESkWSw5IgBHjx61OWz8Upf4+Hi1oxJRM/ALmokAdOvWjbsKiTSI7+SIiEizWHJERKRZLDkiItIslhwREWkWS46IiDSLJUdERJrFkiMiIs1iyRERkWax5IiISLNYckREpFksOSIi0iyWHBERaRZLjoiINIslR0REmsWf2nECSUlJ/BXhVi4/Px/Ar78qTa4rIyMDUVFRaseg/8N3ciqLjY1FSEiI2jHIzgoKCrBt27ZLzg8JCUFsbKwDE5G9REVFoX///mrHoP+jCH8pksjuUlNTERcXxx9mJXKsNL6TIyIizWLJERGRZrHkiIhIs1hyRESkWSw5IiLSLJYcERFpFkuOiIg0iyVHRESaxZIjIiLNYskREZFmseSIiEizWHJERKRZLDkiItIslhwREWkWS46IiDSLJUdERJrFkiMiIs1iyRERkWax5IiISLNYckREpFksOSIi0iyWHBERaRZLjoiINIslR0REmsWSIyIizWLJERGRZrHkiIhIs1hyRESkWSw5IiLSLJYcERFpFkuOiIg0iyVHRESaxZIjIiLNclc7AJHW/PTTT7j33nthsVis0y5cuAAfHx/07NnTZtlbbrkFb731lqMjErUaLDmiFtaxY0dUVVXhyJEjDeZ99913Nn/HxcU5KhZRq8TdlUR2MHXqVLi7X/l/SJYckX2x5Ijs4IEHHkBdXd0l5yuKgltvvRVdunRxYCqi1oclR2QHYWFh6Nu3L9zcGn+K6XQ6TJ061cGpiFoflhyRnUydOhWKojQ6r66uDhMmTHBwIqLWhyVHZCcTJ05sdLpOp8Mdd9yBDh06ODgRUevDkiOyk8DAQAwePBg6na7BvClTpqiQiKj1YckR2dGUKVMgIjbT3NzcMH78eJUSEbUuLDkiOxo/frzNqQTu7u4YOXIk/P39VUxF1Hqw5IjsyNfXF/fccw88PDwA/HLAyeTJk1VORdR6sOSI7GzSpEmora0FABgMBtxzzz0qJyJqPVhyRHY2atQoGI1GAEBMTAy8vLxUTkTUevC7K6lFpaamqh3BKfXt2xe7d+9GaGgo76NGhIaGon///mrHIA1S5PeHfhFdg0ud/Ex0ObGxsUhLS1M7BmlPGndXUoszm80QEV5+c6mtrcWzzz7L+6eRS2xsrMpbLGkZS47IAXQ6HZ566im1YxC1Oiw5Igdpyk/vEFHLYskREZFmseSIiEizWHJERKRZLDkiItIslhwREWkWS46IiDSLJUdERJrFkiMiIs1iyRERkWax5IiISLNYckREpFksOSIi0iyWHJGT2rx5MyIiIqAois3F09MT7dq1w+DBg5GYmIiSkhK1oxI5LZYckZOKiYnB8ePHERkZCT8/P4gI6uvrUVRUhNTUVISHhyMhIQHdu3fH119/rXZcIqfEkiNNqaysRHR0tMuPcSmKosDf3x+DBw/Gxo0bkZqaitOnT2P06NEoLS1VJRORM2PJkaYkJyejqKjI5cdoqtjYWEybNg1FRUV4/fXX1Y5D5HRYcqQqEcHKlStx4403Qq/Xo02bNrjvvvtw9OhR6zKPPfYYPD09ERQUZJ32yCOPwNvbG4qi4OeffwYAzJs3D/Pnz0dubi4URUHnzp2xatUqGAwGtGvXDrNnz0ZwcDAMBgOio6Oxb9++FhlDbdOmTQMAfPjhh9ZpdXV1WLp0KcLCwuDl5YVevXrBbDYDANauXQtvb28YjUZs3boVI0eOhMlkQkhICFJSUmxue8+ePejXrx+MRiNMJhN69uyJsrKyK45B5DSEqAUBELPZ3OTlly5dKp6envLWW2/JuXPnJDMzU2699Va57rrrpLCw0LrcpEmTpH379jbXTUxMFABy5swZ67SYmBiJjIy0WW7WrFni7e0thw8flqqqKsnKypK+ffuKr6+vnDx5skXGaKrm3j8iIpGRkeLn53fJ+WVlZQJAQkNDrdMWLFgger1eNm3aJCUlJbJo0SJxc3OT/fv3i4jI4sWLBYDs2rVLSktLpaioSAYNGiTe3t5SU1MjIiLnz58Xk8kkK1askMrKSiksLJTx48db74srjdFUsbGxEhsb26zrEDVRKt/JkWoqKyuxcuVKjB8/HpMnT4afnx969uyJ119/HT///DPWrVvXYmO5u7tb3y3edNNNWLt2LcrLy7Fx48YWG0Mtvr6+UBQF5eXlAICqqiqsXbsW48aNQ0xMDPz9/bFkyRJ4eHg0WN/o6GiYTCYEBgYiPj4eFy5cwMmTJwEAeXl5KCsrQ/fu3WEwGNC+fXts3rwZ1113XbPGIFITS45Uk5WVhfPnz6NPnz420/v27QtPT0+b3YktrU+fPjAajTa7RV3VhQsXICIwmUwAgOzsbFRUVKBHjx7WZby8vBAUFHTZ9fX09AQAWCwWAEBERATatWuHyZMnY9myZcjLy7Mue7VjEDkaS45Uc+7cOQCAj49Pg3n+/v7Wdyb2otfrcebMGbuO4Qg5OTkAgG7dugH4pfQAYMmSJTbn1504cQIVFRVNvl0vLy98+umnGDhwIJYvX46IiAjEx8ejsrKyxcYgsjeWHKnG398fABots3PnziEkJMRuY1ssFruP4SgfffQRAGDkyJEAgMDAQABAUlISRMTmkp6e3qzb7t69O7Zv346CggIkJCTAbDbjpZdeatExiOyJJUeq6dGjB3x8fBqcyLxv3z7U1NTgD3/4g3Wau7u7dTdaS9i9ezdEBFFRUXYbwxEKCwuRlJSEkJAQPPTQQwCA0NBQGAwGHDx48Jpuu6CgAIcPHwbwS3G++OKLuPXWW3H48OEWG4PI3lhypBqDwYD58+fjvffew9tvv42ysjIcOnQIc+bMQXBwMGbNmmVdtnPnzjh79iy2bNkCi8WCM2fO4MSJEw1uMyAgAAUFBcjLy0N5ebm1tOrr61FSUoLa2lpkZmZi3rx5CAsLsx5+3xJj2JOI4Pz586ivr4eI4MyZMzCbzRgwYAB0Oh22bNli/UzOYDBg+vTpSElJwdq1a1FWVoa6ujrk5+fj1KlTTR6zoKAAs2fPxtGjR1FTU4MDBw7gxIkTiIqKarExiOxOnaM6SavQzEPk6+vrJTExUbp06SIeHh7Spk0bGTdunGRnZ9ssV1xcLEOGDBGDwSDh4eHy6KOPysKFCwWAdO7c2XoqwDfffCOdOnUSLy8vGThwoBQWFsqsWbPEw8NDOnbsKO7u7mIymeS+++6T3NzcFhvDHvfPtm3bpFevXmI0GsXT01Pc3NwEgCiKIv7+rc8vgQAAAYdJREFU/tKvXz959tlnpbi4uMF1q6urJSEhQcLCwsTd3V0CAwMlJiZGsrKyZM2aNWI0GgWAdOnSRXJzc2XdunViMpkEgHTq1ElycnIkLy9PoqOjpU2bNqLT6aRDhw6yePFiqa2tveIYzcFTCMiOUhURERU7ljRGURSYzWZMnDhR7ShWs2fPRlpaGoqLi9WO4pT3j9omTJgAAEhLS1M5CWlQGndXUqtQV1endgQiUgFLjoiINIslR5q2aNEibNy4EaWlpQgPD8emTZvUjkREDuSudgAie3rhhRfwwgsvqB2DiFTCd3JERKRZLDkiItIslhwREWkWS46IiDSLJUdERJrFkiMiIs1iyRERkWax5IiISLNYckREpFksOSIi0iyWHBERaRZLjoiINIslR0REmsVfIaAWl56ernYEp8b7x1Z+fj5CQkLUjkEapYiIqB2CtENRFLUjkAuKjY1FWlqa2jFIe9L4To5aFP9nIiJnws/kiIhIs1hyRESkWSw5IiLSLJYcERFp1v8HbmLXJAvwzOwAAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "\n",
        "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
        "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
        "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
        "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
        "\n",
        "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
        "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
        "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
        "y_pred = model.predict((X_new_A, X_new_B))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Immh3qHzwKo",
        "outputId": "40303b48-038e-4cc8-9c74-d92d45c17fd7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 2.0090 - val_loss: 0.9850\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.7896 - val_loss: 0.7180\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 3s 9ms/step - loss: 0.6514 - val_loss: 0.6402\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5991 - val_loss: 0.5778\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5671 - val_loss: 0.5449\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.5423 - val_loss: 0.5190\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5228 - val_loss: 0.5011\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.5073 - val_loss: 0.4808\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.4945 - val_loss: 0.4661\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4841 - val_loss: 0.4553\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4758 - val_loss: 0.4457\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4687 - val_loss: 0.4377\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4627 - val_loss: 0.4322\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4579 - val_loss: 0.4273\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4536 - val_loss: 0.4230\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4500 - val_loss: 0.4185\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4466 - val_loss: 0.4177\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4441 - val_loss: 0.4169\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4409 - val_loss: 0.4134\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4386 - val_loss: 0.4224\n",
            "162/162 [==============================] - 0s 1ms/step - loss: 0.4297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we want 2 outputs from the model (regression + classification task or indipendent tasks or regularization technique)\n",
        "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
        "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
        "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
        "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
        "concat = keras.layers.concatenate([input_A, hidden2])\n",
        "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
        "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
        "model = keras.models.Model(inputs=[input_A, input_B],\n",
        "                           outputs=[output, aux_output])\n",
        "\n",
        "keras.utils.plot_model(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "J-_deg4bz5bY",
        "outputId": "bd65db22-e822-4327-afab-61d6d0498c81"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we have to specify 2 loss function or keras will use the same, we can say that\n",
        "#we care more about the first output than the 2nd with loss_weights\n",
        "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
      ],
      "metadata": {
        "id": "cmr-6zQK1_E0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
        "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ses5GsfB3KgB",
        "outputId": "c17d7cad-75ce-4ed9-8f0e-8db467fb23a6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 2s 3ms/step - loss: 2.2680 - main_output_loss: 1.9510 - aux_output_loss: 5.1214 - val_loss: 2.7346 - val_main_output_loss: 2.1457 - val_aux_output_loss: 8.0346\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 1.0709 - main_output_loss: 0.8465 - aux_output_loss: 3.0910 - val_loss: 1.5914 - val_main_output_loss: 0.8960 - val_aux_output_loss: 7.8500\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.8526 - main_output_loss: 0.7034 - aux_output_loss: 2.1957 - val_loss: 1.2902 - val_main_output_loss: 0.6649 - val_aux_output_loss: 6.9176\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.7558 - main_output_loss: 0.6404 - aux_output_loss: 1.7942 - val_loss: 1.1200 - val_main_output_loss: 0.6066 - val_aux_output_loss: 5.7407\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.6982 - main_output_loss: 0.5992 - aux_output_loss: 1.5896 - val_loss: 0.9833 - val_main_output_loss: 0.5615 - val_aux_output_loss: 4.7794\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.6574 - main_output_loss: 0.5669 - aux_output_loss: 1.4721 - val_loss: 0.8677 - val_main_output_loss: 0.5297 - val_aux_output_loss: 3.9097\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.6254 - main_output_loss: 0.5402 - aux_output_loss: 1.3918 - val_loss: 0.7787 - val_main_output_loss: 0.5055 - val_aux_output_loss: 3.2383\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.6002 - main_output_loss: 0.5186 - aux_output_loss: 1.3346 - val_loss: 0.7052 - val_main_output_loss: 0.4850 - val_aux_output_loss: 2.6866\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5792 - main_output_loss: 0.5004 - aux_output_loss: 1.2885 - val_loss: 0.6510 - val_main_output_loss: 0.4694 - val_aux_output_loss: 2.2860\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.5624 - main_output_loss: 0.4860 - aux_output_loss: 1.2507 - val_loss: 0.6120 - val_main_output_loss: 0.4594 - val_aux_output_loss: 1.9857\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.5492 - main_output_loss: 0.4748 - aux_output_loss: 1.2187 - val_loss: 0.5858 - val_main_output_loss: 0.4553 - val_aux_output_loss: 1.7601\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.5385 - main_output_loss: 0.4661 - aux_output_loss: 1.1900 - val_loss: 0.5600 - val_main_output_loss: 0.4461 - val_aux_output_loss: 1.5852\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.5297 - main_output_loss: 0.4593 - aux_output_loss: 1.1639 - val_loss: 0.5469 - val_main_output_loss: 0.4467 - val_aux_output_loss: 1.4489\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5224 - main_output_loss: 0.4538 - aux_output_loss: 1.1393 - val_loss: 0.5355 - val_main_output_loss: 0.4452 - val_aux_output_loss: 1.3485\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.5164 - main_output_loss: 0.4496 - aux_output_loss: 1.1168 - val_loss: 0.5250 - val_main_output_loss: 0.4424 - val_aux_output_loss: 1.2683\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.5112 - main_output_loss: 0.4464 - aux_output_loss: 1.0948 - val_loss: 0.5162 - val_main_output_loss: 0.4401 - val_aux_output_loss: 1.2009\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.5072 - main_output_loss: 0.4442 - aux_output_loss: 1.0744 - val_loss: 0.5111 - val_main_output_loss: 0.4403 - val_aux_output_loss: 1.1488\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5030 - main_output_loss: 0.4418 - aux_output_loss: 1.0545 - val_loss: 0.5101 - val_main_output_loss: 0.4437 - val_aux_output_loss: 1.1072\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.4988 - main_output_loss: 0.4392 - aux_output_loss: 1.0355 - val_loss: 0.5025 - val_main_output_loss: 0.4395 - val_aux_output_loss: 1.0689\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4961 - main_output_loss: 0.4382 - aux_output_loss: 1.0178 - val_loss: 0.5110 - val_main_output_loss: 0.4522 - val_aux_output_loss: 1.0409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_loss, main_loss, aux_loss = model.evaluate(\n",
        "    [X_test_A, X_test_B], [y_test, y_test])\n",
        "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMkj1tPn3NEv",
        "outputId": "39e9bd75-a103-429c-867b-4fad09456ace"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 1s 5ms/step - loss: 0.4880 - main_output_loss: 0.4318 - aux_output_loss: 0.9943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# subclassing API to build dynamic models\n",
        "class WideAndDeep(keras.Model):\n",
        "  def __init__(self, units=30, activation='relu', **kwargs):\n",
        "    super().__init__(**kwargs) #handles standard args like name\n",
        "    self.hidden1 = keras.layers.Dense(units, activation= activation)\n",
        "    self.hidden2 = keras.layers.Dense(units, activation= activation)\n",
        "    self.main_output = keras.layers.Dense(1)\n",
        "    self.aux_output = keras.layers.Dense(1)\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    input_A, input_B = inputs\n",
        "    hidden1 = self.hidden1(input_B)\n",
        "    hidden2 = self.hidden2(hidden1)\n",
        "    concat = keras.layers.concatenate([input_A, hidden2])\n",
        "    main_output = self.main_output(concat)\n",
        "    aux_output = self.aux_output(hidden2)\n",
        "    return main_output, aux_output\n",
        "\n",
        "model = WideAndDeep(30, activation='relu')\n"
      ],
      "metadata": {
        "id": "W9fT9bbI3Wi3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"mse\", loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "history = model.fit((X_train_A, X_train_B), (y_train, y_train), epochs=10,\n",
        "                    validation_data=((X_valid_A, X_valid_B), (y_valid, y_valid)))\n",
        "total_loss, main_loss, aux_loss = model.evaluate((X_test_A, X_test_B), (y_test, y_test))\n",
        "y_pred_main, y_pred_aux = model.predict((X_new_A, X_new_B))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXWH_4zhfBEm",
        "outputId": "c033d679-4f6c-4158-da25-ac400126ef89"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "363/363 [==============================] - 3s 4ms/step - loss: 2.1210 - output_1_loss: 1.9986 - output_2_loss: 3.2225 - val_loss: 2.8539 - val_output_1_loss: 2.5208 - val_output_2_loss: 5.8515\n",
            "Epoch 2/10\n",
            "363/363 [==============================] - 3s 7ms/step - loss: 0.9263 - output_1_loss: 0.7926 - output_2_loss: 2.1300 - val_loss: 1.5743 - val_output_1_loss: 1.2249 - val_output_2_loss: 4.7190\n",
            "Epoch 3/10\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.7806 - output_1_loss: 0.6730 - output_2_loss: 1.7492 - val_loss: 1.1348 - val_output_1_loss: 0.8106 - val_output_2_loss: 4.0528\n",
            "Epoch 4/10\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.7027 - output_1_loss: 0.6126 - output_2_loss: 1.5139 - val_loss: 0.9375 - val_output_1_loss: 0.6529 - val_output_2_loss: 3.4992\n",
            "Epoch 5/10\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.6474 - output_1_loss: 0.5703 - output_2_loss: 1.3416 - val_loss: 0.7974 - val_output_1_loss: 0.5528 - val_output_2_loss: 2.9988\n",
            "Epoch 6/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6064 - output_1_loss: 0.5384 - output_2_loss: 1.2180 - val_loss: 0.7264 - val_output_1_loss: 0.5128 - val_output_2_loss: 2.6496\n",
            "Epoch 7/10\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.5766 - output_1_loss: 0.5151 - output_2_loss: 1.1304 - val_loss: 0.6632 - val_output_1_loss: 0.4782 - val_output_2_loss: 2.3281\n",
            "Epoch 8/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5544 - output_1_loss: 0.4977 - output_2_loss: 1.0644 - val_loss: 0.6274 - val_output_1_loss: 0.4627 - val_output_2_loss: 2.1100\n",
            "Epoch 9/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5371 - output_1_loss: 0.4840 - output_2_loss: 1.0154 - val_loss: 0.6025 - val_output_1_loss: 0.4536 - val_output_2_loss: 1.9429\n",
            "Epoch 10/10\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.5239 - output_1_loss: 0.4735 - output_2_loss: 0.9772 - val_loss: 0.5817 - val_output_1_loss: 0.4456 - val_output_2_loss: 1.8068\n",
            "162/162 [==============================] - 0s 1ms/step - loss: 0.5130 - output_1_loss: 0.4627 - output_2_loss: 0.9656\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5174c0cef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#saving and restoring a model\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
        "    keras.layers.Dense(30, activation=\"relu\"),\n",
        "    keras.layers.Dense(1)\n",
        "])    \n",
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3chhNOpfIJj",
        "outputId": "45937cb1-cb77-4649-f152-d671e211b594"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "363/363 [==============================] - 3s 5ms/step - loss: 1.7708 - val_loss: 0.7858\n",
            "Epoch 2/10\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.7263 - val_loss: 0.6888\n",
            "Epoch 3/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6499 - val_loss: 0.6225\n",
            "Epoch 4/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6047 - val_loss: 0.5610\n",
            "Epoch 5/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5699 - val_loss: 0.5240\n",
            "Epoch 6/10\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.5404 - val_loss: 0.4974\n",
            "Epoch 7/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5160 - val_loss: 0.4785\n",
            "Epoch 8/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4956 - val_loss: 0.4574\n",
            "Epoch 9/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4784 - val_loss: 0.4423\n",
            "Epoch 10/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4640 - val_loss: 0.4303\n",
            "162/162 [==============================] - 0s 2ms/step - loss: 0.4448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"my_keras_model.h5\")\n",
        "model = keras.models.load_model(\"my_keras_model.h5\")\n",
        "model.predict(X_new)\n",
        "model.save_weights(\"my_keras_weights.ckpt\")\n",
        "model.load_weights(\"my_keras_weights.ckpt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaJnr4Fbjevu",
        "outputId": "4f77d527-be47-4e4a-da33-de010dbbc70b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f51749efb00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7777176],\n",
              "       [1.5822685],\n",
              "       [3.3043728]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using callbacks\n",
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
        "    keras.layers.Dense(30, activation=\"relu\"),\n",
        "    keras.layers.Dense(1)\n",
        "])    \n",
        "\n",
        "#save only the best parameters that perform better on validation, simple early stop\n",
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[checkpoint_cb])\n",
        "model = keras.models.load_model(\"my_keras_model.h5\") # rollback to best model\n",
        "mse_test = model.evaluate(X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CzawNxKjmRT",
        "outputId": "0bf99f88-5be2-433c-9505-844adac79b2d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "363/363 [==============================] - 4s 10ms/step - loss: 1.8866 - val_loss: 0.7126\n",
            "Epoch 2/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6577 - val_loss: 0.6880\n",
            "Epoch 3/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5934 - val_loss: 0.5803\n",
            "Epoch 4/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5557 - val_loss: 0.5166\n",
            "Epoch 5/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5272 - val_loss: 0.4895\n",
            "Epoch 6/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5033 - val_loss: 0.4951\n",
            "Epoch 7/10\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4854 - val_loss: 0.4861\n",
            "Epoch 8/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4709 - val_loss: 0.4554\n",
            "Epoch 9/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4578 - val_loss: 0.4413\n",
            "Epoch 10/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4474 - val_loss: 0.4379\n",
            "162/162 [==============================] - 0s 2ms/step - loss: 0.4382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#early stopping\n",
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
        "                                                  restore_best_weights=True)\n",
        "history = model.fit(X_train, y_train, epochs=100,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awoQLmCEoueT",
        "outputId": "9207dcc8-fbe4-4858-d750-360d253d46ed"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "363/363 [==============================] - 7s 15ms/step - loss: 0.4393 - val_loss: 0.4110\n",
            "Epoch 2/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4315 - val_loss: 0.4266\n",
            "Epoch 3/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4259 - val_loss: 0.3996\n",
            "Epoch 4/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4201 - val_loss: 0.3939\n",
            "Epoch 5/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4154 - val_loss: 0.3889\n",
            "Epoch 6/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4111 - val_loss: 0.3866\n",
            "Epoch 7/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4074 - val_loss: 0.3860\n",
            "Epoch 8/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4040 - val_loss: 0.3793\n",
            "Epoch 9/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4008 - val_loss: 0.3746\n",
            "Epoch 10/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3976 - val_loss: 0.3723\n",
            "Epoch 11/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3950 - val_loss: 0.3697\n",
            "Epoch 12/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3923 - val_loss: 0.3669\n",
            "Epoch 13/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3897 - val_loss: 0.3661\n",
            "Epoch 14/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3874 - val_loss: 0.3631\n",
            "Epoch 15/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3851 - val_loss: 0.3660\n",
            "Epoch 16/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3829 - val_loss: 0.3625\n",
            "Epoch 17/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3810 - val_loss: 0.3592\n",
            "Epoch 18/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3788 - val_loss: 0.3563\n",
            "Epoch 19/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3766 - val_loss: 0.3535\n",
            "Epoch 20/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3750 - val_loss: 0.3709\n",
            "Epoch 21/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3732 - val_loss: 0.3512\n",
            "Epoch 22/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3715 - val_loss: 0.3699\n",
            "Epoch 23/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3700 - val_loss: 0.3476\n",
            "Epoch 24/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3685 - val_loss: 0.3561\n",
            "Epoch 25/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3671 - val_loss: 0.3527\n",
            "Epoch 26/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3658 - val_loss: 0.3700\n",
            "Epoch 27/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3647 - val_loss: 0.3432\n",
            "Epoch 28/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3635 - val_loss: 0.3592\n",
            "Epoch 29/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3625 - val_loss: 0.3521\n",
            "Epoch 30/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3613 - val_loss: 0.3626\n",
            "Epoch 31/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3601 - val_loss: 0.3431\n",
            "Epoch 32/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3589 - val_loss: 0.3766\n",
            "Epoch 33/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3584 - val_loss: 0.3374\n",
            "Epoch 34/100\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 0.3572 - val_loss: 0.3407\n",
            "Epoch 35/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3563 - val_loss: 0.3614\n",
            "Epoch 36/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3555 - val_loss: 0.3348\n",
            "Epoch 37/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3546 - val_loss: 0.3573\n",
            "Epoch 38/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3538 - val_loss: 0.3367\n",
            "Epoch 39/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3530 - val_loss: 0.3425\n",
            "Epoch 40/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3523 - val_loss: 0.3368\n",
            "Epoch 41/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3515 - val_loss: 0.3514\n",
            "Epoch 42/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3511 - val_loss: 0.3426\n",
            "Epoch 43/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3500 - val_loss: 0.3677\n",
            "Epoch 44/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3496 - val_loss: 0.3563\n",
            "Epoch 45/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3490 - val_loss: 0.3336\n",
            "Epoch 46/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3481 - val_loss: 0.3456\n",
            "Epoch 47/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3478 - val_loss: 0.3433\n",
            "Epoch 48/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3471 - val_loss: 0.3658\n",
            "Epoch 49/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3466 - val_loss: 0.3286\n",
            "Epoch 50/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3460 - val_loss: 0.3268\n",
            "Epoch 51/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3454 - val_loss: 0.3438\n",
            "Epoch 52/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3449 - val_loss: 0.3262\n",
            "Epoch 53/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3444 - val_loss: 0.3909\n",
            "Epoch 54/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3439 - val_loss: 0.3275\n",
            "Epoch 55/100\n",
            "363/363 [==============================] - 2s 7ms/step - loss: 0.3435 - val_loss: 0.3559\n",
            "Epoch 56/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3430 - val_loss: 0.3237\n",
            "Epoch 57/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3423 - val_loss: 0.3242\n",
            "Epoch 58/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3419 - val_loss: 0.3766\n",
            "Epoch 59/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3417 - val_loss: 0.3289\n",
            "Epoch 60/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3410 - val_loss: 0.3501\n",
            "Epoch 61/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3404 - val_loss: 0.3456\n",
            "Epoch 62/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3402 - val_loss: 0.3445\n",
            "Epoch 63/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3392 - val_loss: 0.3290\n",
            "Epoch 64/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3393 - val_loss: 0.3217\n",
            "Epoch 65/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3387 - val_loss: 0.3351\n",
            "Epoch 66/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3383 - val_loss: 0.3232\n",
            "Epoch 67/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3376 - val_loss: 0.3566\n",
            "Epoch 68/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3374 - val_loss: 0.3257\n",
            "Epoch 69/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3370 - val_loss: 0.3349\n",
            "Epoch 70/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3365 - val_loss: 0.3560\n",
            "Epoch 71/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3361 - val_loss: 0.3581\n",
            "Epoch 72/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3357 - val_loss: 0.3288\n",
            "Epoch 73/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3351 - val_loss: 0.3203\n",
            "Epoch 74/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3350 - val_loss: 0.3840\n",
            "Epoch 75/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3347 - val_loss: 0.3233\n",
            "Epoch 76/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3342 - val_loss: 0.3476\n",
            "Epoch 77/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3338 - val_loss: 0.3408\n",
            "Epoch 78/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3335 - val_loss: 0.3463\n",
            "Epoch 79/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3332 - val_loss: 0.3347\n",
            "Epoch 80/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3329 - val_loss: 0.3353\n",
            "Epoch 81/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3324 - val_loss: 0.3276\n",
            "Epoch 82/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3320 - val_loss: 0.3167\n",
            "Epoch 83/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3317 - val_loss: 0.3280\n",
            "Epoch 84/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3312 - val_loss: 0.3636\n",
            "Epoch 85/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3310 - val_loss: 0.3176\n",
            "Epoch 86/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3308 - val_loss: 0.3156\n",
            "Epoch 87/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3305 - val_loss: 0.3529\n",
            "Epoch 88/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3299 - val_loss: 0.3255\n",
            "Epoch 89/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3294 - val_loss: 0.3627\n",
            "Epoch 90/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3296 - val_loss: 0.3377\n",
            "Epoch 91/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3292 - val_loss: 0.3211\n",
            "Epoch 92/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3287 - val_loss: 0.3455\n",
            "Epoch 93/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3285 - val_loss: 0.3158\n",
            "Epoch 94/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3281 - val_loss: 0.3409\n",
            "Epoch 95/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3277 - val_loss: 0.3378\n",
            "Epoch 96/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3273 - val_loss: 0.3214\n",
            "162/162 [==============================] - 0s 2ms/step - loss: 0.3310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#custom control\n",
        "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))\n",
        "\n",
        "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
        "history = model.fit(X_train, y_train, epochs=1,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[val_train_ratio_cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6CdqnP0pMl5",
        "outputId": "55657081-cf40-44a5-b48e-ec4d9bbca8b9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "354/363 [============================>.] - ETA: 0s - loss: 0.3286\n",
            "val/train: 1.08\n",
            "363/363 [==============================] - 3s 9ms/step - loss: 0.3302 - val_loss: 0.3561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#use tensorboard for visualization\n",
        "import os\n",
        "import time\n",
        "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
        "def get_run_logdir():\n",
        "  run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "  return os.path.join(root_logdir, run_id)\n",
        "\n",
        "run_logdir = get_run_logdir()\n",
        "print(run_logdir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkT9i9QStCyy",
        "outputId": "f8f636c3-ca10-436c-dde8-5bb8ed47ce15"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./my_logs/run_2022_04_06-16_57_12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
        "    keras.layers.Dense(30, activation=\"relu\"),\n",
        "    keras.layers.Dense(1)\n",
        "])    \n",
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "history = model.fit(X_train, y_train, epochs=30,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[checkpoint_cb, tensorboard_cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzs7dOLWy9KI",
        "outputId": "eb63ce6f-6c4b-4a6a-a034-378babd9a9aa"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 1.8866 - val_loss: 0.7126\n",
            "Epoch 2/30\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.6577 - val_loss: 0.6880\n",
            "Epoch 3/30\n",
            "363/363 [==============================] - 2s 7ms/step - loss: 0.5934 - val_loss: 0.5803\n",
            "Epoch 4/30\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.5557 - val_loss: 0.5166\n",
            "Epoch 5/30\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.5272 - val_loss: 0.4895\n",
            "Epoch 6/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5033 - val_loss: 0.4951\n",
            "Epoch 7/30\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4854 - val_loss: 0.4861\n",
            "Epoch 8/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4709 - val_loss: 0.4554\n",
            "Epoch 9/30\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4578 - val_loss: 0.4413\n",
            "Epoch 10/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4474 - val_loss: 0.4379\n",
            "Epoch 11/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4393 - val_loss: 0.4396\n",
            "Epoch 12/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4318 - val_loss: 0.4507\n",
            "Epoch 13/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4261 - val_loss: 0.3997\n",
            "Epoch 14/30\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4202 - val_loss: 0.3956\n",
            "Epoch 15/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4155 - val_loss: 0.3916\n",
            "Epoch 16/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4112 - val_loss: 0.3937\n",
            "Epoch 17/30\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4077 - val_loss: 0.3809\n",
            "Epoch 18/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4040 - val_loss: 0.3793\n",
            "Epoch 19/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4004 - val_loss: 0.3850\n",
            "Epoch 20/30\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3980 - val_loss: 0.3809\n",
            "Epoch 21/30\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3949 - val_loss: 0.3701\n",
            "Epoch 22/30\n",
            "363/363 [==============================] - 3s 7ms/step - loss: 0.3924 - val_loss: 0.3781\n",
            "Epoch 23/30\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3898 - val_loss: 0.3650\n",
            "Epoch 24/30\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3874 - val_loss: 0.3655\n",
            "Epoch 25/30\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3851 - val_loss: 0.3611\n",
            "Epoch 26/30\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3829 - val_loss: 0.3626\n",
            "Epoch 27/30\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 0.3809 - val_loss: 0.3564\n",
            "Epoch 28/30\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3788 - val_loss: 0.3579\n",
            "Epoch 29/30\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3769 - val_loss: 0.3561\n",
            "Epoch 30/30\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 0.3750 - val_loss: 0.3548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run tensorboard on jupyter\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir=./content/my_logs --port=6008"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "j9gcnMNTz8oe",
        "outputId": "4d041eab-5aea-4d80-e0a2-8a1f4f2458c4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ERROR: Failed to launch TensorBoard (exited with 255).\n",
              "Contents of stderr:\n",
              "2022-04-06 17:06:28.067120: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
              "\n",
              "NOTE: Using experimental fast data loading logic. To disable, pass\n",
              "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
              "    https://github.com/tensorflow/tensorboard/issues/4784\n",
              "\n",
              "E0406 17:06:28.543416 139713471588224 program.py:298] TensorBoard could not bind to port 6008, it was already in use\n",
              "ERROR: TensorBoard could not bind to port 6008, it was already in use"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs\n",
        "#doesn't work on colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        },
        "id": "OKQhxw120Jns",
        "outputId": "b6274b44-7bd4-4160-b714-ca861b8a22b3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6009, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_logdir2 = get_run_logdir()\n",
        "run_logdir2\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
        "    keras.layers.Dense(30, activation=\"relu\"),\n",
        "    keras.layers.Dense(1)\n",
        "])    \n",
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=0.05))\n",
        "\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir2)\n",
        "history = model.fit(X_train, y_train, epochs=30,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[checkpoint_cb, tensorboard_cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojB3rzGL2OFZ",
        "outputId": "c46074e2-e9ce-469b-e097-f896ad0be041"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.5765 - val_loss: 4.8654\n",
            "Epoch 2/30\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.5506 - val_loss: 2.4561\n",
            "Epoch 3/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4120 - val_loss: 0.3365\n",
            "Epoch 4/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3650 - val_loss: 0.3776\n",
            "Epoch 5/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3574 - val_loss: 0.3306\n",
            "Epoch 6/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3441 - val_loss: 0.3182\n",
            "Epoch 7/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3386 - val_loss: 0.3191\n",
            "Epoch 8/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3321 - val_loss: 0.3063\n",
            "Epoch 9/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3247 - val_loss: 0.2994\n",
            "Epoch 10/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3210 - val_loss: 0.3145\n",
            "Epoch 11/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3185 - val_loss: 0.2986\n",
            "Epoch 12/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3132 - val_loss: 0.2998\n",
            "Epoch 13/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3077 - val_loss: 0.2851\n",
            "Epoch 14/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3048 - val_loss: 0.3803\n",
            "Epoch 15/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3037 - val_loss: 0.2842\n",
            "Epoch 16/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2995 - val_loss: 0.2715\n",
            "Epoch 17/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2970 - val_loss: 0.3066\n",
            "Epoch 18/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2965 - val_loss: 0.2711\n",
            "Epoch 19/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2941 - val_loss: 0.2777\n",
            "Epoch 20/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2930 - val_loss: 0.3156\n",
            "Epoch 21/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2905 - val_loss: 0.2960\n",
            "Epoch 22/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2881 - val_loss: 0.5802\n",
            "Epoch 23/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2898 - val_loss: 0.3228\n",
            "Epoch 24/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2862 - val_loss: 0.2773\n",
            "Epoch 25/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2862 - val_loss: 0.2713\n",
            "Epoch 26/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2855 - val_loss: 0.2728\n",
            "Epoch 27/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2814 - val_loss: 0.2913\n",
            "Epoch 28/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2808 - val_loss: 0.5011\n",
            "Epoch 29/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2807 - val_loss: 0.2788\n",
            "Epoch 30/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2807 - val_loss: 0.7564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameter tuning\n",
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
        "    for layer in range(n_hidden):\n",
        "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
        "    model.add(keras.layers.Dense(1))\n",
        "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "    return model\n",
        "\n",
        "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
        "keras_reg.fit(X_train, y_train, epochs=100,\n",
        "              validation_data=(X_valid, y_valid),\n",
        "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ScSgwI52mQo",
        "outputId": "4b6235d6-06f9-496a-d65f-8ff8de2addff"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "363/363 [==============================] - 2s 4ms/step - loss: 1.0896 - val_loss: 20.7721\n",
            "Epoch 2/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.7606 - val_loss: 5.0266\n",
            "Epoch 3/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.5456 - val_loss: 0.5490\n",
            "Epoch 4/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4732 - val_loss: 0.4529\n",
            "Epoch 5/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4503 - val_loss: 0.4188\n",
            "Epoch 6/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4338 - val_loss: 0.4129\n",
            "Epoch 7/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4241 - val_loss: 0.4004\n",
            "Epoch 8/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4168 - val_loss: 0.3944\n",
            "Epoch 9/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4108 - val_loss: 0.3961\n",
            "Epoch 10/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4060 - val_loss: 0.4071\n",
            "Epoch 11/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4021 - val_loss: 0.3855\n",
            "Epoch 12/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3984 - val_loss: 0.4136\n",
            "Epoch 13/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3951 - val_loss: 0.3997\n",
            "Epoch 14/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3921 - val_loss: 0.3818\n",
            "Epoch 15/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3894 - val_loss: 0.3829\n",
            "Epoch 16/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3869 - val_loss: 0.3739\n",
            "Epoch 17/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3848 - val_loss: 0.4022\n",
            "Epoch 18/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3829 - val_loss: 0.3873\n",
            "Epoch 19/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3807 - val_loss: 0.3768\n",
            "Epoch 20/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3791 - val_loss: 0.4191\n",
            "Epoch 21/100\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 0.3774 - val_loss: 0.3927\n",
            "Epoch 22/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3756 - val_loss: 0.4237\n",
            "Epoch 23/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3742 - val_loss: 0.3523\n",
            "Epoch 24/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3725 - val_loss: 0.3842\n",
            "Epoch 25/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3710 - val_loss: 0.4162\n",
            "Epoch 26/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3700 - val_loss: 0.3980\n",
            "Epoch 27/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3691 - val_loss: 0.3474\n",
            "Epoch 28/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3677 - val_loss: 0.3920\n",
            "Epoch 29/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3670 - val_loss: 0.3566\n",
            "Epoch 30/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3653 - val_loss: 0.4191\n",
            "Epoch 31/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3647 - val_loss: 0.3721\n",
            "Epoch 32/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3633 - val_loss: 0.3948\n",
            "Epoch 33/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3632 - val_loss: 0.3423\n",
            "Epoch 34/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3617 - val_loss: 0.3453\n",
            "Epoch 35/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3610 - val_loss: 0.4068\n",
            "Epoch 36/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3608 - val_loss: 0.3417\n",
            "Epoch 37/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3596 - val_loss: 0.3787\n",
            "Epoch 38/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3589 - val_loss: 0.3379\n",
            "Epoch 39/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3582 - val_loss: 0.3419\n",
            "Epoch 40/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3572 - val_loss: 0.3705\n",
            "Epoch 41/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3570 - val_loss: 0.3659\n",
            "Epoch 42/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3563 - val_loss: 0.3803\n",
            "Epoch 43/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3552 - val_loss: 0.3765\n",
            "Epoch 44/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3548 - val_loss: 0.3813\n",
            "Epoch 45/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3543 - val_loss: 0.3326\n",
            "Epoch 46/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3532 - val_loss: 0.3385\n",
            "Epoch 47/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3527 - val_loss: 0.3655\n",
            "Epoch 48/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3521 - val_loss: 0.3579\n",
            "Epoch 49/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3525 - val_loss: 0.3360\n",
            "Epoch 50/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3510 - val_loss: 0.3317\n",
            "Epoch 51/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3504 - val_loss: 0.3562\n",
            "Epoch 52/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3502 - val_loss: 0.3521\n",
            "Epoch 53/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3496 - val_loss: 0.4579\n",
            "Epoch 54/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3497 - val_loss: 0.3809\n",
            "Epoch 55/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3490 - val_loss: 0.3540\n",
            "Epoch 56/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3485 - val_loss: 0.3725\n",
            "Epoch 57/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3478 - val_loss: 0.3337\n",
            "Epoch 58/100\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 0.3469 - val_loss: 0.4011\n",
            "Epoch 59/100\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 0.3476 - val_loss: 0.3263\n",
            "Epoch 60/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3466 - val_loss: 0.3271\n",
            "Epoch 61/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3453 - val_loss: 0.3349\n",
            "Epoch 62/100\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 0.3454 - val_loss: 0.3541\n",
            "Epoch 63/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3445 - val_loss: 0.3428\n",
            "Epoch 64/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3451 - val_loss: 0.3280\n",
            "Epoch 65/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3437 - val_loss: 0.3292\n",
            "Epoch 66/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3431 - val_loss: 0.3301\n",
            "Epoch 67/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3428 - val_loss: 0.3254\n",
            "Epoch 68/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3423 - val_loss: 0.3245\n",
            "Epoch 69/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3419 - val_loss: 0.3255\n",
            "Epoch 70/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3413 - val_loss: 0.3666\n",
            "Epoch 71/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3414 - val_loss: 0.3370\n",
            "Epoch 72/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3405 - val_loss: 0.3267\n",
            "Epoch 73/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3400 - val_loss: 0.3245\n",
            "Epoch 74/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3402 - val_loss: 0.3663\n",
            "Epoch 75/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3397 - val_loss: 0.3290\n",
            "Epoch 76/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3395 - val_loss: 0.3235\n",
            "Epoch 77/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3383 - val_loss: 0.3386\n",
            "Epoch 78/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3384 - val_loss: 0.3362\n",
            "Epoch 79/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3384 - val_loss: 0.3222\n",
            "Epoch 80/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3376 - val_loss: 0.3644\n",
            "Epoch 81/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3384 - val_loss: 0.3420\n",
            "Epoch 82/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3371 - val_loss: 0.3253\n",
            "Epoch 83/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3368 - val_loss: 0.3246\n",
            "Epoch 84/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3362 - val_loss: 0.3953\n",
            "Epoch 85/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3372 - val_loss: 0.3415\n",
            "Epoch 86/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3359 - val_loss: 0.3190\n",
            "Epoch 87/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3356 - val_loss: 0.3277\n",
            "Epoch 88/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3351 - val_loss: 0.3295\n",
            "Epoch 89/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3348 - val_loss: 0.3247\n",
            "Epoch 90/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3344 - val_loss: 0.3281\n",
            "Epoch 91/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3341 - val_loss: 0.3201\n",
            "Epoch 92/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3338 - val_loss: 0.3393\n",
            "Epoch 93/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3336 - val_loss: 0.3170\n",
            "Epoch 94/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3334 - val_loss: 0.3526\n",
            "Epoch 95/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3329 - val_loss: 0.4813\n",
            "Epoch 96/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3339 - val_loss: 0.3465\n",
            "Epoch 97/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3324 - val_loss: 0.4632\n",
            "Epoch 98/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3333 - val_loss: 0.6725\n",
            "Epoch 99/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3330 - val_loss: 0.5924\n",
            "Epoch 100/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3343 - val_loss: 0.5272\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5174e6fc10>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse_test = keras_reg.score(X_test, y_test)\n",
        "y_pred = keras_reg.predict(X_new)\n",
        "\n",
        "#Warning: the following cell crashes at the end of training. This seems to be caused by Keras issue #13586, which was triggered by a recent change in Scikit-Learn. Pull Request #13598 seems to fix the issue, so this problem should be resolved soon. In the meantime, I've added .tolist() and .rvs(1000).tolist() as workarounds.\n",
        "from scipy.stats import reciprocal\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_distribs = {\n",
        "    \"n_hidden\": [0, 1, 2, 3],\n",
        "    \"n_neurons\": np.arange(1, 100)               .tolist(),\n",
        "    \"learning_rate\": reciprocal(3e-4, 3e-2)      .rvs(1000).tolist(),\n",
        "}\n",
        "\n",
        "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
        "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
        "                  validation_data=(X_valid, y_valid),\n",
        "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
        "\n",
        "print(rnd_search_cv.best_params_)\n",
        "print(rnd_search_cv.best_score_)\n",
        "print(rnd_search_cv.best_estimator_)\n",
        "print(rnd_search_cv.score(X_test, y_test))\n",
        "model = rnd_search_cv.best_estimator_.model\n",
        "print(model)\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lClw_CSO6gSi",
        "outputId": "a8bddd2b-8f1a-4731-be01-94cf1d38dde2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 0s 2ms/step - loss: 0.3346\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.7861 - val_loss: 0.4686\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4791 - val_loss: 0.4998\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4595 - val_loss: 0.4157\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4497 - val_loss: 0.4080\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4455 - val_loss: 0.5519\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4427 - val_loss: 0.4784\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4468 - val_loss: 0.5038\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4394 - val_loss: 0.6504\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4631 - val_loss: 0.4199\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4528 - val_loss: 0.5007\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4414 - val_loss: 0.5845\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4419 - val_loss: 0.4339\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4601 - val_loss: 0.4623\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4415 - val_loss: 0.4809\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.4551\n",
            "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=  11.2s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8053 - val_loss: 0.4446\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4572 - val_loss: 0.4158\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4376 - val_loss: 0.3959\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4300 - val_loss: 0.3926\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4283 - val_loss: 0.3928\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4243 - val_loss: 0.3911\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4223 - val_loss: 0.3937\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4213 - val_loss: 0.3834\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4193 - val_loss: 0.3840\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4206 - val_loss: 0.3852\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4199 - val_loss: 0.3839\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4175 - val_loss: 0.3882\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4163 - val_loss: 0.3934\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4139 - val_loss: 0.3865\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4109 - val_loss: 0.3787\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4091 - val_loss: 0.3781\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4110 - val_loss: 0.3746\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4102 - val_loss: 0.3765\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4057 - val_loss: 0.3753\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4027 - val_loss: 0.3751\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4033 - val_loss: 0.3786\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4013 - val_loss: 0.3695\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4005 - val_loss: 0.3714\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3968 - val_loss: 0.3648\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3947 - val_loss: 0.3798\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3936 - val_loss: 0.3642\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3906 - val_loss: 0.3624\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3908 - val_loss: 0.3580\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3917 - val_loss: 0.3607\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3932 - val_loss: 0.3853\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3862 - val_loss: 0.3992\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3886 - val_loss: 0.3994\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3850 - val_loss: 0.4901\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.4705\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3854 - val_loss: 0.5281\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.5601\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3822 - val_loss: 0.6549\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3817 - val_loss: 0.6047\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.4075\n",
            "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=  20.6s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.2946 - val_loss: 12.7473\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7094 - val_loss: 5.5930\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5759 - val_loss: 0.4561\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4526 - val_loss: 0.3987\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4298 - val_loss: 0.3912\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4166 - val_loss: 0.3894\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4137 - val_loss: 0.3827\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4245 - val_loss: 0.3973\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4184 - val_loss: 0.3805\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4156 - val_loss: 0.3751\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4038 - val_loss: 0.3739\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4012 - val_loss: 0.3732\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3997 - val_loss: 0.3781\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3975 - val_loss: 0.3738\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3958 - val_loss: 0.3723\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4001 - val_loss: 0.3723\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3951 - val_loss: 0.3719\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3929 - val_loss: 0.3717\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3929 - val_loss: 0.3629\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3901 - val_loss: 0.3627\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4040 - val_loss: 0.3646\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3893 - val_loss: 0.3610\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3880 - val_loss: 0.3590\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3871 - val_loss: 0.3621\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3902 - val_loss: 0.3609\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3903 - val_loss: 0.3605\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3886 - val_loss: 0.3618\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3863 - val_loss: 0.3622\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4029 - val_loss: 0.3574\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3858 - val_loss: 0.3561\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3844 - val_loss: 0.3645\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3900 - val_loss: 0.3552\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3873 - val_loss: 0.3657\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3934 - val_loss: 0.3619\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3841 - val_loss: 0.3574\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3816 - val_loss: 0.3531\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3828 - val_loss: 0.3704\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3860 - val_loss: 0.3533\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3818 - val_loss: 0.3523\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3810 - val_loss: 0.3531\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3802 - val_loss: 0.3529\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3799 - val_loss: 0.3524\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3847 - val_loss: 0.3527\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3794 - val_loss: 0.3511\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3816 - val_loss: 0.3543\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3795 - val_loss: 0.3509\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3789 - val_loss: 0.3492\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3787 - val_loss: 0.3494\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3781 - val_loss: 0.3601\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3865 - val_loss: 0.3525\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3795 - val_loss: 0.3525\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3791 - val_loss: 0.3516\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3795 - val_loss: 0.3503\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3845 - val_loss: 0.3905\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4265 - val_loss: 0.3610\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3874 - val_loss: 0.3558\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3880 - val_loss: 0.3526\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3746\n",
            "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=  41.5s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 1.1145 - val_loss: 7.0347\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6442 - val_loss: 7.5879\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5361 - val_loss: 0.4715\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4254 - val_loss: 0.3821\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4021 - val_loss: 0.3746\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3892 - val_loss: 0.4037\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3807 - val_loss: 0.3758\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3734 - val_loss: 0.3965\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3687 - val_loss: 0.3791\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3646 - val_loss: 0.3873\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3622 - val_loss: 0.3440\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3572 - val_loss: 0.3594\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3536 - val_loss: 0.3718\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3523 - val_loss: 0.3684\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3490 - val_loss: 0.3500\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3471 - val_loss: 0.3653\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3444 - val_loss: 0.3543\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3425 - val_loss: 0.3560\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3404 - val_loss: 0.3485\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3380 - val_loss: 0.3526\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3376 - val_loss: 0.3444\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3574\n",
            "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  21.1s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 1.0005 - val_loss: 0.9596\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5063 - val_loss: 0.7571\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4379 - val_loss: 0.7232\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4091 - val_loss: 0.4714\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3912 - val_loss: 0.3650\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3792 - val_loss: 0.4524\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3720 - val_loss: 0.6994\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3643 - val_loss: 0.8516\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3577 - val_loss: 1.0870\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3540 - val_loss: 0.8715\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3487 - val_loss: 1.0093\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3446 - val_loss: 1.0464\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3422 - val_loss: 1.2565\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3403 - val_loss: 1.1147\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3379 - val_loss: 1.1346\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3616\n",
            "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  11.0s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 1.0109 - val_loss: 9.2330\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5932 - val_loss: 11.2919\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5470 - val_loss: 2.4708\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4562 - val_loss: 4.1857\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4401 - val_loss: 1.1614\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4064 - val_loss: 0.3633\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3857 - val_loss: 0.3785\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3781 - val_loss: 0.3907\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3717 - val_loss: 0.4213\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3706 - val_loss: 0.3678\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3647 - val_loss: 0.4243\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3609 - val_loss: 0.3900\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3572 - val_loss: 0.3698\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3547 - val_loss: 0.4033\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3529 - val_loss: 0.3433\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3491 - val_loss: 0.3805\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3465 - val_loss: 0.3555\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3454 - val_loss: 0.3429\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3422 - val_loss: 0.3831\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3397 - val_loss: 0.3609\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3403 - val_loss: 0.3359\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3370 - val_loss: 0.3347\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3344 - val_loss: 0.3289\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3339 - val_loss: 0.3561\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3316 - val_loss: 0.3159\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3294 - val_loss: 0.3262\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3275 - val_loss: 0.3719\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3267 - val_loss: 0.3173\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3252 - val_loss: 0.3771\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3248 - val_loss: 0.3192\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3225 - val_loss: 0.3304\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3203 - val_loss: 0.3433\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3210 - val_loss: 0.3222\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3179 - val_loss: 0.3591\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3182 - val_loss: 0.3077\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3149 - val_loss: 0.3438\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3142 - val_loss: 0.3136\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3131 - val_loss: 0.4009\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3131 - val_loss: 0.3025\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3121 - val_loss: 0.3557\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3094 - val_loss: 0.3305\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3086 - val_loss: 0.3295\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3108 - val_loss: 0.3048\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3070 - val_loss: 0.3598\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3101 - val_loss: 0.3048\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3053 - val_loss: 0.4918\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3059 - val_loss: 0.4324\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3062 - val_loss: 0.3592\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3027 - val_loss: 0.3195\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3183\n",
            "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  31.4s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 3.4511 - val_loss: 4.9424\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.6083 - val_loss: 3.3453\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.0809 - val_loss: 2.1447\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8926 - val_loss: 1.3870\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8097 - val_loss: 0.9902\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7662 - val_loss: 0.8069\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7394 - val_loss: 0.7225\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7204 - val_loss: 0.6864\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7053 - val_loss: 0.6691\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6922 - val_loss: 0.6575\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6804 - val_loss: 0.6497\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6696 - val_loss: 0.6399\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6595 - val_loss: 0.6335\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6500 - val_loss: 0.6260\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6411 - val_loss: 0.6160\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6326 - val_loss: 0.6094\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6245 - val_loss: 0.6016\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6167 - val_loss: 0.5956\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6093 - val_loss: 0.5883\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6022 - val_loss: 0.5825\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5954 - val_loss: 0.5726\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5888 - val_loss: 0.5667\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5825 - val_loss: 0.5604\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5763 - val_loss: 0.5561\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5707 - val_loss: 0.5477\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5650 - val_loss: 0.5394\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5596 - val_loss: 0.5359\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5546 - val_loss: 0.5276\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5495 - val_loss: 0.5229\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5448 - val_loss: 0.5181\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5402 - val_loss: 0.5138\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5358 - val_loss: 0.5082\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5316 - val_loss: 0.5040\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5275 - val_loss: 0.4994\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5236 - val_loss: 0.4946\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5198 - val_loss: 0.4914\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5162 - val_loss: 0.4862\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5126 - val_loss: 0.4836\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5092 - val_loss: 0.4799\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5059 - val_loss: 0.4764\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5027 - val_loss: 0.4739\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4997 - val_loss: 0.4705\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4968 - val_loss: 0.4675\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4939 - val_loss: 0.4651\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4911 - val_loss: 0.4627\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4885 - val_loss: 0.4599\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4859 - val_loss: 0.4574\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4834 - val_loss: 0.4549\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4811 - val_loss: 0.4527\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4787 - val_loss: 0.4505\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4765 - val_loss: 0.4482\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4743 - val_loss: 0.4457\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4722 - val_loss: 0.4436\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4701 - val_loss: 0.4416\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4682 - val_loss: 0.4398\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4662 - val_loss: 0.4378\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4644 - val_loss: 0.4360\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4626 - val_loss: 0.4343\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4608 - val_loss: 0.4326\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4591 - val_loss: 0.4310\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4575 - val_loss: 0.4295\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4559 - val_loss: 0.4281\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4543 - val_loss: 0.4265\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4528 - val_loss: 0.4252\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4513 - val_loss: 0.4239\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4498 - val_loss: 0.4224\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4484 - val_loss: 0.4213\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4471 - val_loss: 0.4206\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4457 - val_loss: 0.4191\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4444 - val_loss: 0.4180\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4432 - val_loss: 0.4169\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4419 - val_loss: 0.4160\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4407 - val_loss: 0.4146\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4395 - val_loss: 0.4139\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4384 - val_loss: 0.4130\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4372 - val_loss: 0.4119\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4362 - val_loss: 0.4111\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4352 - val_loss: 0.4106\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4341 - val_loss: 0.4099\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4331 - val_loss: 0.4090\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4321 - val_loss: 0.4086\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4312 - val_loss: 0.4089\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4303 - val_loss: 0.4080\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4293 - val_loss: 0.4073\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4284 - val_loss: 0.4060\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4275 - val_loss: 0.4063\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4267 - val_loss: 0.4049\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4259 - val_loss: 0.4037\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4251 - val_loss: 0.4024\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4242 - val_loss: 0.4025\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4235 - val_loss: 0.4010\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4227 - val_loss: 0.4006\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4219 - val_loss: 0.4004\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4212 - val_loss: 0.3997\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4205 - val_loss: 0.3992\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4197 - val_loss: 0.3988\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4190 - val_loss: 0.3979\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4183 - val_loss: 0.3968\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4176 - val_loss: 0.3983\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4170 - val_loss: 0.3969\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.4252\n",
            "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  57.9s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 3.9665 - val_loss: 14.2647\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.0674 - val_loss: 17.6519\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.3965 - val_loss: 17.9204\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.1058 - val_loss: 16.5763\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9582 - val_loss: 14.5937\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8746 - val_loss: 12.6168\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8231 - val_loss: 10.8348\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7882 - val_loss: 9.2089\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7621 - val_loss: 7.8337\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7410 - val_loss: 6.6503\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7229 - val_loss: 5.6413\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7067 - val_loss: 4.7267\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6921 - val_loss: 3.9819\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6786 - val_loss: 3.3573\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6660 - val_loss: 2.8087\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6542 - val_loss: 2.3628\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6431 - val_loss: 1.9732\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6327 - val_loss: 1.6502\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6228 - val_loss: 1.3794\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6135 - val_loss: 1.1636\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6047 - val_loss: 0.9777\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5964 - val_loss: 0.8380\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5885 - val_loss: 0.7262\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5810 - val_loss: 0.6465\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5738 - val_loss: 0.5877\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5670 - val_loss: 0.5509\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5605 - val_loss: 0.5319\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5543 - val_loss: 0.5279\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5483 - val_loss: 0.5347\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5428 - val_loss: 0.5533\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5374 - val_loss: 0.5828\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5323 - val_loss: 0.6162\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5274 - val_loss: 0.6565\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5227 - val_loss: 0.6944\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5182 - val_loss: 0.7370\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5139 - val_loss: 0.7881\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5098 - val_loss: 0.8358\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5058 - val_loss: 0.8856\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.5197\n",
            "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  22.8s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 4.7382 - val_loss: 7.1880\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.5680 - val_loss: 4.4809\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.6134 - val_loss: 2.2749\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.1515 - val_loss: 1.3999\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9270 - val_loss: 0.9174\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8120 - val_loss: 0.7630\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7503 - val_loss: 0.7085\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7147 - val_loss: 0.6973\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6927 - val_loss: 0.6716\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6766 - val_loss: 0.6475\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6636 - val_loss: 0.6500\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6533 - val_loss: 0.6334\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6435 - val_loss: 0.6176\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6346 - val_loss: 0.6100\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6264 - val_loss: 0.5993\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6186 - val_loss: 0.5986\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6114 - val_loss: 0.5889\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6043 - val_loss: 0.5808\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5974 - val_loss: 0.5837\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5913 - val_loss: 0.5710\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5850 - val_loss: 0.5625\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5790 - val_loss: 0.5601\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5733 - val_loss: 0.5487\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5677 - val_loss: 0.5412\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5624 - val_loss: 0.5375\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5573 - val_loss: 0.5308\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5523 - val_loss: 0.5331\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5477 - val_loss: 0.5275\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5431 - val_loss: 0.5243\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5387 - val_loss: 0.5186\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5344 - val_loss: 0.5167\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5303 - val_loss: 0.5124\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5263 - val_loss: 0.5091\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5226 - val_loss: 0.5040\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5189 - val_loss: 0.5025\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5154 - val_loss: 0.4915\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5120 - val_loss: 0.4859\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5086 - val_loss: 0.4859\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5054 - val_loss: 0.4816\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5024 - val_loss: 0.4785\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4993 - val_loss: 0.4761\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4965 - val_loss: 0.4719\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4937 - val_loss: 0.4686\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4910 - val_loss: 0.4669\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4884 - val_loss: 0.4659\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4860 - val_loss: 0.4631\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4835 - val_loss: 0.4571\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4812 - val_loss: 0.4557\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4789 - val_loss: 0.4534\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4767 - val_loss: 0.4512\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4745 - val_loss: 0.4486\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4725 - val_loss: 0.4467\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4705 - val_loss: 0.4442\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4686 - val_loss: 0.4417\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4666 - val_loss: 0.4396\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4648 - val_loss: 0.4376\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4631 - val_loss: 0.4359\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4614 - val_loss: 0.4346\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4597 - val_loss: 0.4327\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4581 - val_loss: 0.4317\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4566 - val_loss: 0.4294\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4551 - val_loss: 0.4279\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4537 - val_loss: 0.4265\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4522 - val_loss: 0.4251\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4509 - val_loss: 0.4238\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4495 - val_loss: 0.4228\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4483 - val_loss: 0.4212\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4470 - val_loss: 0.4199\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4458 - val_loss: 0.4189\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4446 - val_loss: 0.4176\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4434 - val_loss: 0.4168\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4424 - val_loss: 0.4155\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4412 - val_loss: 0.4142\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4402 - val_loss: 0.4133\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4391 - val_loss: 0.4124\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4381 - val_loss: 0.4121\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4371 - val_loss: 0.4107\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4361 - val_loss: 0.4092\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4351 - val_loss: 0.4087\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4342 - val_loss: 0.4080\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4333 - val_loss: 0.4067\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4324 - val_loss: 0.4057\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4315 - val_loss: 0.4050\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4307 - val_loss: 0.4043\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4298 - val_loss: 0.4034\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4290 - val_loss: 0.4025\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4282 - val_loss: 0.4026\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4274 - val_loss: 0.4011\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4266 - val_loss: 0.4015\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4259 - val_loss: 0.4003\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4251 - val_loss: 0.3992\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4244 - val_loss: 0.3983\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4237 - val_loss: 0.3977\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4230 - val_loss: 0.3973\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4222 - val_loss: 0.3972\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4216 - val_loss: 0.3967\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4209 - val_loss: 0.3965\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4202 - val_loss: 0.3949\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4196 - val_loss: 0.3944\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4190 - val_loss: 0.3943\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.4218\n",
            "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time= 1.4min\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.6618 - val_loss: 1.8499\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6841 - val_loss: 0.6056\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5964 - val_loss: 0.5409\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5447 - val_loss: 0.4957\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5048 - val_loss: 0.4613\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4754 - val_loss: 0.4689\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4536 - val_loss: 0.4310\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4366 - val_loss: 0.4383\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4242 - val_loss: 0.4249\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4142 - val_loss: 0.4376\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4067 - val_loss: 0.3994\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3999 - val_loss: 0.3947\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3942 - val_loss: 0.4215\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3897 - val_loss: 0.4456\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3855 - val_loss: 0.4176\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3818 - val_loss: 0.4174\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3783 - val_loss: 0.4419\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3755 - val_loss: 0.4020\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3720 - val_loss: 0.4218\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3699 - val_loss: 0.4121\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3673 - val_loss: 0.4182\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3653 - val_loss: 0.3999\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3824\n",
            "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=  14.3s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.9727 - val_loss: 9.4104\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7668 - val_loss: 3.2179\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6602 - val_loss: 0.9574\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6042 - val_loss: 0.5583\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5601 - val_loss: 0.8146\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5247 - val_loss: 1.0712\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4962 - val_loss: 1.4011\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4732 - val_loss: 1.5949\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4551 - val_loss: 1.5080\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4414 - val_loss: 1.4165\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4299 - val_loss: 1.2768\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4206 - val_loss: 1.1615\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4132 - val_loss: 1.0189\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4071 - val_loss: 0.6850\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.4243\n",
            "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=   9.2s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.7919 - val_loss: 1.3486\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6894 - val_loss: 0.6096\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6148 - val_loss: 0.5617\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5746 - val_loss: 0.5285\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5407 - val_loss: 0.5029\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5135 - val_loss: 0.4783\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4903 - val_loss: 0.4483\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4724 - val_loss: 0.4335\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4573 - val_loss: 0.4553\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4457 - val_loss: 0.4091\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4359 - val_loss: 0.4300\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4274 - val_loss: 0.4173\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4196 - val_loss: 0.3870\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4144 - val_loss: 0.4552\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4096 - val_loss: 0.3793\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4041 - val_loss: 0.4105\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4006 - val_loss: 0.3714\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3966 - val_loss: 0.3782\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3933 - val_loss: 0.4079\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3896 - val_loss: 0.3753\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3873 - val_loss: 0.3710\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3848 - val_loss: 0.3634\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3821 - val_loss: 0.3600\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3788 - val_loss: 0.4176\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3780 - val_loss: 0.3502\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3750 - val_loss: 0.3501\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3728 - val_loss: 0.4235\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3725 - val_loss: 0.3543\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3690 - val_loss: 0.4418\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3693 - val_loss: 0.3562\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3662 - val_loss: 0.3544\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3648 - val_loss: 0.3916\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3630 - val_loss: 0.3669\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3618 - val_loss: 0.4061\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3616 - val_loss: 0.3464\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3591 - val_loss: 0.3461\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3585 - val_loss: 0.3364\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3567 - val_loss: 0.4128\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3563 - val_loss: 0.3341\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3543 - val_loss: 0.3593\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3530 - val_loss: 0.3769\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3522 - val_loss: 0.3719\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3509 - val_loss: 0.3319\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3501 - val_loss: 0.3790\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3495 - val_loss: 0.3426\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3482 - val_loss: 0.3667\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3472 - val_loss: 0.3300\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3468 - val_loss: 0.3283\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3451 - val_loss: 0.4153\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3456 - val_loss: 0.3439\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3438 - val_loss: 0.3833\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3438 - val_loss: 0.3492\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3431 - val_loss: 0.3251\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3423 - val_loss: 0.3240\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3412 - val_loss: 0.3279\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3401 - val_loss: 0.3529\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3400 - val_loss: 0.3651\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3398 - val_loss: 0.3357\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3386 - val_loss: 0.3517\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3383 - val_loss: 0.3213\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3374 - val_loss: 0.3279\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3364 - val_loss: 0.3652\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3369 - val_loss: 0.3221\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3358 - val_loss: 0.3341\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3353 - val_loss: 0.3289\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3345 - val_loss: 0.3759\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3344 - val_loss: 0.3258\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3334 - val_loss: 0.3780\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3331 - val_loss: 0.3309\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3320 - val_loss: 0.3838\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3344\n",
            "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=  42.9s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.3543 - val_loss: 278.0078\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.0067 - val_loss: 468.5057\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 5.7017 - val_loss: 3357.5913\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 10.6236 - val_loss: 10779.4434\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 48.7160 - val_loss: 54721.0312\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2026.6531 - val_loss: 238651.0312\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2457.8982 - val_loss: 1077017.8750\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 35898.2695 - val_loss: 4813696.0000\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 74477.9766 - val_loss: 21807908.0000\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 939328.6250 - val_loss: 106617360.0000\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1655600.3750 - val_loss: 471392000.0000\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 1247940.3750\n",
            "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=   6.2s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9404 - val_loss: 12.5308\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5479 - val_loss: 22.0424\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5146 - val_loss: 24.7323\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5129 - val_loss: 22.4188\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5110 - val_loss: 21.8068\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5095 - val_loss: 21.1836\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5115 - val_loss: 19.8238\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5104 - val_loss: 22.4320\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5069 - val_loss: 20.0577\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5088 - val_loss: 10.6991\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5083 - val_loss: 19.7108\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5049 - val_loss: 24.3061\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5077 - val_loss: 25.9355\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5199 - val_loss: 10.5239\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5078 - val_loss: 17.1876\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5064 - val_loss: 21.8309\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5058 - val_loss: 11.7730\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5101 - val_loss: 14.1544\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5071 - val_loss: 20.9801\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5032 - val_loss: 12.3616\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5071 - val_loss: 25.9139\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5132 - val_loss: 16.0458\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5071 - val_loss: 19.4875\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5084 - val_loss: 12.1053\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.7813\n",
            "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=  21.1s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.1959 - val_loss: 220.2773\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7949 - val_loss: 47.8077\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.2426 - val_loss: 633.5494\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 27.7870 - val_loss: 567.5355\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.1771 - val_loss: 2368.0388\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 8.1419 - val_loss: 1264.0120\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 4.3366 - val_loss: 1367.0508\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 37.1192 - val_loss: 1248.9767\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 9.9760 - val_loss: 1204.7947\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.3894 - val_loss: 172.6834\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 11.2886 - val_loss: 95.7204\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6338 - val_loss: 0.4980\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7299 - val_loss: 728.3746\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 8.4135 - val_loss: 426.6041\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2.1307 - val_loss: 1014.9500\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 35.2207 - val_loss: 820.1584\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 8.6242 - val_loss: 1080.5728\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 3.6469 - val_loss: 471.8724\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 23.5580 - val_loss: 290.1389\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 3.3776 - val_loss: 327.0032\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 4.0866 - val_loss: 527.9959\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 4.2748 - val_loss: 369.9812\n",
            "121/121 [==============================] - 1s 6ms/step - loss: 0.6076\n",
            "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=  12.5s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.0977 - val_loss: 9.3560\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5933 - val_loss: 4.9114\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6608 - val_loss: 23.6918\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6247 - val_loss: 0.8305\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4367 - val_loss: 0.4382\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4073 - val_loss: 0.3789\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3918 - val_loss: 0.3650\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3801 - val_loss: 0.3782\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3730 - val_loss: 0.3859\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3669 - val_loss: 0.3838\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3614 - val_loss: 0.3799\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3557 - val_loss: 0.3739\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3514 - val_loss: 0.3684\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3485 - val_loss: 0.3815\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3451 - val_loss: 0.3500\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3424 - val_loss: 0.3688\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3398 - val_loss: 0.3639\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3378 - val_loss: 0.3512\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3350 - val_loss: 0.3409\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3334 - val_loss: 0.3364\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3318 - val_loss: 0.3862\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3318 - val_loss: 0.3225\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3289 - val_loss: 0.3539\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3292 - val_loss: 0.3265\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3263 - val_loss: 0.3378\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3243 - val_loss: 0.3316\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3238 - val_loss: 0.3370\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3222 - val_loss: 0.3732\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3211 - val_loss: 0.3212\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3194 - val_loss: 0.3192\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3185 - val_loss: 0.3129\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3181 - val_loss: 0.3094\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3169 - val_loss: 0.3183\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3152 - val_loss: 0.3133\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3150 - val_loss: 0.3208\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3154 - val_loss: 0.3282\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3133 - val_loss: 0.3208\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3122 - val_loss: 0.3396\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3130 - val_loss: 0.3171\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3130 - val_loss: 0.3383\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3113 - val_loss: 0.3406\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3089 - val_loss: 0.3263\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3416\n",
            "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=  41.7s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.1302 - val_loss: 5.3405\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5966 - val_loss: 1.9179\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5180 - val_loss: 0.8584\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4696 - val_loss: 0.5011\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4384 - val_loss: 0.4179\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4192 - val_loss: 0.3957\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4076 - val_loss: 0.3840\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3978 - val_loss: 0.3829\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3891 - val_loss: 0.3984\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3832 - val_loss: 0.4012\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3768 - val_loss: 0.4176\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3715 - val_loss: 0.4585\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3695 - val_loss: 0.4881\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3664 - val_loss: 0.5506\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3638 - val_loss: 0.5670\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3599 - val_loss: 0.6044\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3576 - val_loss: 0.6272\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3554 - val_loss: 0.6610\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3718\n",
            "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=  11.3s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.3901 - val_loss: 1.0742\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5807 - val_loss: 1.5461\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5096 - val_loss: 2.1300\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4760 - val_loss: 0.5628\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4291 - val_loss: 0.5440\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4107 - val_loss: 0.3782\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3975 - val_loss: 0.3642\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3880 - val_loss: 0.3605\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3796 - val_loss: 0.3808\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3749 - val_loss: 0.3647\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3687 - val_loss: 0.4351\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3650 - val_loss: 0.3404\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3592 - val_loss: 0.3379\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3556 - val_loss: 0.4752\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3542 - val_loss: 0.4051\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3498 - val_loss: 0.4980\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3490 - val_loss: 0.3755\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3432 - val_loss: 0.3919\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3421 - val_loss: 0.3231\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3398 - val_loss: 0.4009\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3380 - val_loss: 0.3204\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3355 - val_loss: 0.3375\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3330 - val_loss: 0.4217\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3340 - val_loss: 0.3141\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3317 - val_loss: 0.3660\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3279 - val_loss: 0.3567\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3261 - val_loss: 0.3141\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3256 - val_loss: 0.4675\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3271 - val_loss: 1.1325\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3327 - val_loss: 0.6169\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3250 - val_loss: 0.5854\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3235 - val_loss: 0.3285\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3185 - val_loss: 0.6138\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3227 - val_loss: 0.4237\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3168\n",
            "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=  20.6s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.8293 - val_loss: 0.7707\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7152 - val_loss: 1.2274\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6247 - val_loss: 0.6900\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5804 - val_loss: 1.4336\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5373 - val_loss: 0.7951\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5150 - val_loss: 1.0350\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4824 - val_loss: 0.8966\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4763 - val_loss: 1.4385\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4578 - val_loss: 0.7174\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4480 - val_loss: 1.2468\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4390 - val_loss: 1.0594\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4354 - val_loss: 1.7422\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4340 - val_loss: 1.2544\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.4328\n",
            "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=  10.9s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.7049 - val_loss: 1.6499\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7067 - val_loss: 0.7040\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6335 - val_loss: 0.7033\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5893 - val_loss: 1.1895\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5547 - val_loss: 1.7099\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5290 - val_loss: 2.0733\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5091 - val_loss: 2.3126\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4929 - val_loss: 2.4700\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4794 - val_loss: 2.3367\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4689 - val_loss: 2.2179\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4592 - val_loss: 2.0412\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4508 - val_loss: 1.9741\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4444 - val_loss: 1.7869\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.4915\n",
            "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=  10.9s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.0996 - val_loss: 23.0700\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.0033 - val_loss: 18.5943\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8020 - val_loss: 5.3541\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6801 - val_loss: 1.2951\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5753 - val_loss: 0.5321\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5412 - val_loss: 0.5037\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5148 - val_loss: 0.4787\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4935 - val_loss: 0.5109\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4784 - val_loss: 0.4881\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4634 - val_loss: 0.4455\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4516 - val_loss: 0.4218\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4424 - val_loss: 0.4376\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4346 - val_loss: 0.4147\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4289 - val_loss: 0.4338\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4237 - val_loss: 0.4053\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4190 - val_loss: 0.4070\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4152 - val_loss: 0.3942\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4126 - val_loss: 0.3978\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4100 - val_loss: 0.4030\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4069 - val_loss: 0.3992\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4047 - val_loss: 0.3995\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4030 - val_loss: 0.3817\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4008 - val_loss: 0.3997\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3985 - val_loss: 0.4051\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3971 - val_loss: 0.3777\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3951 - val_loss: 0.3837\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3937 - val_loss: 0.4195\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3928 - val_loss: 0.3900\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3910 - val_loss: 0.4373\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3910 - val_loss: 0.3913\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3886 - val_loss: 0.3857\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3876 - val_loss: 0.4213\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3861 - val_loss: 0.3998\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3858 - val_loss: 0.4277\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3855 - val_loss: 0.3803\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3814\n",
            "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=  20.1s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.1022 - val_loss: 8.2027\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6115 - val_loss: 3.9992\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4705 - val_loss: 0.4696\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4008 - val_loss: 0.3657\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3795 - val_loss: 0.3671\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3684 - val_loss: 0.3926\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3610 - val_loss: 0.3700\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3542 - val_loss: 0.3909\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3492 - val_loss: 0.3803\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3453 - val_loss: 0.3790\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3418 - val_loss: 0.3555\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3369 - val_loss: 0.3720\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3332 - val_loss: 0.3611\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3320 - val_loss: 0.3654\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3282 - val_loss: 0.3615\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3260 - val_loss: 0.3658\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3233 - val_loss: 0.3499\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3213 - val_loss: 0.3770\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3185 - val_loss: 0.3467\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3166 - val_loss: 0.3748\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3150 - val_loss: 0.3307\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3134 - val_loss: 0.4008\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3128 - val_loss: 0.3094\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3110 - val_loss: 0.3256\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3073 - val_loss: 0.3766\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3067 - val_loss: 0.3328\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3065 - val_loss: 0.3634\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3051 - val_loss: 0.3324\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3016 - val_loss: 0.3833\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3026 - val_loss: 0.3554\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3026 - val_loss: 0.3080\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2994 - val_loss: 0.3001\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2970 - val_loss: 0.3368\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2955 - val_loss: 0.3221\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2944 - val_loss: 0.2984\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2933 - val_loss: 0.3754\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2924 - val_loss: 0.3278\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2919 - val_loss: 0.3473\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2901 - val_loss: 0.3001\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2892 - val_loss: 0.3399\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2885 - val_loss: 0.2914\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2868 - val_loss: 0.2985\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2862 - val_loss: 0.2946\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2843 - val_loss: 0.3256\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2838 - val_loss: 0.3008\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2819 - val_loss: 0.3516\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2811 - val_loss: 0.2919\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2797 - val_loss: 0.3265\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2910 - val_loss: 0.4381\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2860 - val_loss: 0.5110\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2827 - val_loss: 0.3015\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3370\n",
            "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=  41.6s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.1172 - val_loss: 1.2402\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5673 - val_loss: 0.6555\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4666 - val_loss: 0.7520\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4240 - val_loss: 0.5613\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3991 - val_loss: 0.4009\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3836 - val_loss: 0.3728\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3736 - val_loss: 0.4705\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3656 - val_loss: 0.6636\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3582 - val_loss: 0.9075\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3537 - val_loss: 0.8736\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3482 - val_loss: 1.0123\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3442 - val_loss: 1.0348\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3416 - val_loss: 1.2307\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3400 - val_loss: 1.1767\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3372 - val_loss: 1.1305\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3336 - val_loss: 1.0777\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3571\n",
            "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=  11.5s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.9098 - val_loss: 1.0813\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5112 - val_loss: 1.0242\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4351 - val_loss: 0.6436\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4014 - val_loss: 0.9093\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3852 - val_loss: 0.6429\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3743 - val_loss: 0.4681\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3646 - val_loss: 0.3390\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3572 - val_loss: 0.3866\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3515 - val_loss: 0.4354\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3511 - val_loss: 0.4639\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3467 - val_loss: 0.7681\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3462 - val_loss: 0.4128\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3386 - val_loss: 0.3587\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3348 - val_loss: 0.4367\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3364 - val_loss: 0.5725\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3360 - val_loss: 0.4420\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3300 - val_loss: 0.3222\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3249 - val_loss: 0.3611\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3238 - val_loss: 0.3631\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3215 - val_loss: 0.3668\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3209 - val_loss: 0.3487\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3192 - val_loss: 0.3376\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3171 - val_loss: 0.5126\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3153 - val_loss: 0.3151\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3120 - val_loss: 0.3098\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3089 - val_loss: 0.3086\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3070 - val_loss: 0.4711\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3104 - val_loss: 0.3900\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3096 - val_loss: 0.6173\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3097 - val_loss: 0.3165\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3050 - val_loss: 0.3943\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3022 - val_loss: 0.3558\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3011 - val_loss: 0.4148\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2988 - val_loss: 0.3178\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2962 - val_loss: 0.3150\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2939 - val_loss: 0.4644\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3052\n",
            "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=  25.5s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.9195 - val_loss: 1.0302\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4885 - val_loss: 1.2004\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4228 - val_loss: 0.3862\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3880 - val_loss: 0.3773\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3712 - val_loss: 0.3671\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3590 - val_loss: 0.3947\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3510 - val_loss: 0.3673\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3437 - val_loss: 0.4154\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3396 - val_loss: 0.3512\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3351 - val_loss: 0.4257\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3339 - val_loss: 0.3227\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3288 - val_loss: 0.3649\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3241 - val_loss: 0.3748\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3227 - val_loss: 0.3491\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3184 - val_loss: 0.3638\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3168 - val_loss: 0.3349\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3137 - val_loss: 0.3761\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3133 - val_loss: 0.3102\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3096 - val_loss: 0.4205\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3114 - val_loss: 0.3028\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3075 - val_loss: 0.4030\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3061 - val_loss: 0.3289\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3029 - val_loss: 0.3575\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3033 - val_loss: 0.3012\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2990 - val_loss: 0.3712\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2970 - val_loss: 0.3178\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2969 - val_loss: 0.3463\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2984 - val_loss: 0.3066\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2943 - val_loss: 0.3779\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2930 - val_loss: 0.3039\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2927 - val_loss: 0.3492\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2907 - val_loss: 0.2889\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2878 - val_loss: 0.3282\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2855 - val_loss: 0.3238\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2851 - val_loss: 0.2914\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2843 - val_loss: 0.3528\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2832 - val_loss: 0.2840\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2810 - val_loss: 0.3827\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2823 - val_loss: 0.3020\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2819 - val_loss: 0.4913\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2836 - val_loss: 0.2984\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2790 - val_loss: 0.3404\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2784 - val_loss: 0.3058\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2779 - val_loss: 0.3963\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2778 - val_loss: 0.2820\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2754 - val_loss: 0.3342\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2732 - val_loss: 0.2978\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2743 - val_loss: 0.2949\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2717 - val_loss: 0.2798\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2723 - val_loss: 0.3431\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2706 - val_loss: 0.3089\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2684 - val_loss: 0.3031\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2688 - val_loss: 0.2870\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2672 - val_loss: 0.3036\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2660 - val_loss: 0.2897\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2675 - val_loss: 0.3056\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2650 - val_loss: 0.2912\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2674 - val_loss: 0.3207\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2653 - val_loss: 0.2799\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3044\n",
            "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=  41.8s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8952 - val_loss: 0.7245\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4801 - val_loss: 0.6150\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4196 - val_loss: 0.5237\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3942 - val_loss: 0.3991\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3770 - val_loss: 0.3593\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3655 - val_loss: 0.4367\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3586 - val_loss: 0.6965\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3521 - val_loss: 0.6864\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3460 - val_loss: 0.8185\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3421 - val_loss: 0.4903\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3368 - val_loss: 0.5677\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3324 - val_loss: 0.6085\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3292 - val_loss: 0.6815\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3270 - val_loss: 0.6250\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3244 - val_loss: 0.5583\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3404\n",
            "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=  21.2s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8971 - val_loss: 1.7172\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4941 - val_loss: 1.5583\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4310 - val_loss: 0.6154\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4010 - val_loss: 0.6663\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3849 - val_loss: 0.3860\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3731 - val_loss: 0.4423\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3659 - val_loss: 0.3418\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3578 - val_loss: 0.3548\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3506 - val_loss: 0.4343\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3492 - val_loss: 0.3982\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3442 - val_loss: 0.5217\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3419 - val_loss: 0.3241\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3362 - val_loss: 0.3347\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3318 - val_loss: 0.4545\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3311 - val_loss: 0.3359\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3268 - val_loss: 0.4315\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3238 - val_loss: 0.3260\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3188 - val_loss: 0.3599\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3177 - val_loss: 0.3281\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3148 - val_loss: 0.4615\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3154 - val_loss: 0.3077\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3104 - val_loss: 0.3243\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3087 - val_loss: 0.3084\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3076 - val_loss: 0.4873\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3069 - val_loss: 0.4338\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3038 - val_loss: 0.7540\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3155 - val_loss: 0.3385\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3037 - val_loss: 0.3478\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3012 - val_loss: 0.3290\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3001 - val_loss: 0.3350\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2970 - val_loss: 0.3005\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2939 - val_loss: 0.4122\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2952 - val_loss: 0.2918\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2902 - val_loss: 0.3845\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2912 - val_loss: 0.3853\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2893 - val_loss: 1.3362\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2932 - val_loss: 1.3598\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3061 - val_loss: 1.1286\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2966 - val_loss: 0.3020\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2874 - val_loss: 0.3481\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2838 - val_loss: 0.3653\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2834 - val_loss: 0.3258\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2811 - val_loss: 0.3104\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.2978\n",
            "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=  41.6s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.2641 - val_loss: 1.0188\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6339 - val_loss: 13.0635\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6143 - val_loss: 2.8437\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4859 - val_loss: 1.1360\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4281 - val_loss: 0.4039\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4030 - val_loss: 0.4145\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3903 - val_loss: 0.3750\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3809 - val_loss: 0.4143\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3749 - val_loss: 0.3871\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3698 - val_loss: 0.3974\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3656 - val_loss: 0.3622\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3610 - val_loss: 0.3556\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3574 - val_loss: 0.3983\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3558 - val_loss: 0.3965\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3523 - val_loss: 0.3751\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3507 - val_loss: 0.3764\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3479 - val_loss: 0.3943\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3466 - val_loss: 0.3712\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3435 - val_loss: 0.4043\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3425 - val_loss: 0.3655\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3405 - val_loss: 0.3574\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3393 - val_loss: 0.3893\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3612\n",
            "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  21.2s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 1.0869 - val_loss: 2.1243\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4915 - val_loss: 0.6432\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4401 - val_loss: 0.6139\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4185 - val_loss: 0.6130\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4037 - val_loss: 0.6604\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3931 - val_loss: 0.9250\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3855 - val_loss: 1.1386\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3785 - val_loss: 1.1547\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3729 - val_loss: 1.2424\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3686 - val_loss: 1.0245\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3635 - val_loss: 1.0676\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3592 - val_loss: 1.1011\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3572 - val_loss: 1.1677\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3543 - val_loss: 1.1376\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3838\n",
            "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  10.0s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.1109 - val_loss: 6.3170\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6194 - val_loss: 2.2062\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4948 - val_loss: 0.4299\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4424 - val_loss: 0.4669\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4195 - val_loss: 0.4019\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4056 - val_loss: 0.4430\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3963 - val_loss: 0.3841\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3889 - val_loss: 0.3949\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3817 - val_loss: 0.4589\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3795 - val_loss: 0.3501\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3726 - val_loss: 0.4816\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3702 - val_loss: 0.3621\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3666 - val_loss: 0.3631\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3628 - val_loss: 0.4434\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3611 - val_loss: 0.3449\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3569 - val_loss: 0.4093\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3547 - val_loss: 0.3487\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3516 - val_loss: 0.3733\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3495 - val_loss: 0.4389\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3478 - val_loss: 0.3561\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3463 - val_loss: 0.3839\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3445 - val_loss: 0.3266\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3420 - val_loss: 0.3779\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3404 - val_loss: 0.4048\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3396 - val_loss: 0.3241\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3368 - val_loss: 0.3521\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3347 - val_loss: 0.4221\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3344 - val_loss: 0.3197\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3335 - val_loss: 0.4195\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3313 - val_loss: 0.3725\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3294 - val_loss: 0.3327\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3276 - val_loss: 0.4332\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3272 - val_loss: 0.3739\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3243 - val_loss: 0.4252\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3249 - val_loss: 0.3122\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3221 - val_loss: 0.4319\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3222 - val_loss: 0.3267\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3222 - val_loss: 0.4653\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3207 - val_loss: 0.3115\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3188 - val_loss: 0.4511\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3180 - val_loss: 0.3230\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3162 - val_loss: 0.4100\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3167 - val_loss: 0.3153\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3148 - val_loss: 0.4828\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3149 - val_loss: 0.3160\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3125 - val_loss: 0.5445\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3122 - val_loss: 0.3982\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3136 - val_loss: 0.4518\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3103 - val_loss: 0.3333\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3204\n",
            "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  41.6s\n",
            "Epoch 1/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.7960 - val_loss: 1.9822\n",
            "Epoch 2/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4733 - val_loss: 4.5379\n",
            "Epoch 3/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4485 - val_loss: 0.7719\n",
            "Epoch 4/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3893 - val_loss: 0.3519\n",
            "Epoch 5/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3728 - val_loss: 0.3632\n",
            "Epoch 6/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3622 - val_loss: 0.3789\n",
            "Epoch 7/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3569 - val_loss: 0.3780\n",
            "Epoch 8/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3501 - val_loss: 0.3725\n",
            "Epoch 9/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3438 - val_loss: 0.3670\n",
            "Epoch 10/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3401 - val_loss: 0.3899\n",
            "Epoch 11/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3363 - val_loss: 0.3289\n",
            "Epoch 12/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3329 - val_loss: 0.3656\n",
            "Epoch 13/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3284 - val_loss: 0.3234\n",
            "Epoch 14/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3246 - val_loss: 0.3149\n",
            "Epoch 15/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3225 - val_loss: 0.3234\n",
            "Epoch 16/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3192 - val_loss: 0.3080\n",
            "Epoch 17/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3169 - val_loss: 0.3506\n",
            "Epoch 18/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3140 - val_loss: 0.3205\n",
            "Epoch 19/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3122 - val_loss: 0.2987\n",
            "Epoch 20/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3098 - val_loss: 0.3755\n",
            "Epoch 21/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3069 - val_loss: 0.3030\n",
            "Epoch 22/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3042 - val_loss: 0.3388\n",
            "Epoch 23/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3026 - val_loss: 0.3140\n",
            "Epoch 24/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3006 - val_loss: 0.3378\n",
            "Epoch 25/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2991 - val_loss: 0.3692\n",
            "Epoch 26/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2969 - val_loss: 0.4093\n",
            "Epoch 27/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2958 - val_loss: 0.3567\n",
            "Epoch 28/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2954 - val_loss: 0.3729\n",
            "Epoch 29/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2931 - val_loss: 0.2912\n",
            "Epoch 30/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2918 - val_loss: 0.3300\n",
            "Epoch 31/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2918 - val_loss: 0.2894\n",
            "Epoch 32/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2891 - val_loss: 0.3398\n",
            "Epoch 33/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2872 - val_loss: 0.2823\n",
            "Epoch 34/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2847 - val_loss: 0.2925\n",
            "Epoch 35/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2842 - val_loss: 0.3485\n",
            "Epoch 36/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2834 - val_loss: 0.2867\n",
            "Epoch 37/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2815 - val_loss: 0.3848\n",
            "Epoch 38/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2793 - val_loss: 0.2805\n",
            "Epoch 39/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2806 - val_loss: 0.3388\n",
            "Epoch 40/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2790 - val_loss: 0.2758\n",
            "Epoch 41/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2791 - val_loss: 0.4322\n",
            "Epoch 42/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2799 - val_loss: 0.2756\n",
            "Epoch 43/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2743 - val_loss: 0.3213\n",
            "Epoch 44/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2757 - val_loss: 0.2822\n",
            "Epoch 45/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2725 - val_loss: 0.5263\n",
            "Epoch 46/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2750 - val_loss: 0.4515\n",
            "Epoch 47/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2759 - val_loss: 0.5378\n",
            "Epoch 48/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2739 - val_loss: 0.2902\n",
            "Epoch 49/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2714 - val_loss: 0.2978\n",
            "Epoch 50/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2714 - val_loss: 0.4562\n",
            "Epoch 51/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2719 - val_loss: 0.4934\n",
            "Epoch 52/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2700 - val_loss: 0.3160\n",
            "{'n_neurons': 80, 'n_hidden': 3, 'learning_rate': 0.0059640580092043885}\n",
            "-0.3141898016134898\n",
            "<keras.wrappers.scikit_learn.KerasRegressor object at 0x7f50eb7fd650>\n",
            "162/162 [==============================] - 0s 2ms/step - loss: 0.2870\n",
            "-0.28699493408203125\n",
            "<keras.engine.sequential.Sequential object at 0x7f50e92d5190>\n",
            "162/162 [==============================] - 0s 2ms/step - loss: 0.2870\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.28699493408203125"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2cZ3LtxH6905"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}